{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <p style=\"background-color:lightgreen;font-family:newtimeroman;color:black;font-size:150%;text-align:center;border-radius:50px 50px;\">Введение в обработку естественного языка</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align='center'>Урок 2. Создание признакового пространства</h2>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3 align='left'>Практическое задание:</h3>  \n",
    "\n",
    "### Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "\n",
    "\n",
    "### Задание 2.\n",
    "\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "\n",
    "\n",
    "### Задание 3.\n",
    "\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера \n",
    "\n",
    "3) убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача: классификация твитов по тональности\n",
    "\n",
    "У нас есть датасет из твитов, про каждый указано, как он эмоционально окрашен: положительно или отрицательно. Задача: предсказывать эмоциональную окраску.\n",
    "\n",
    "Скачиваем куски датасета ([источник](http://study.mokoron.com/)): [положительные](https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv?dl=0), [отрицательные](https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-08 07:39:42--  https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6026:18::a27d:4612, 162.125.70.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6026:18::a27d:4612|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/fnpq3z4bcnoktiv/positive.csv [following]\n",
      "--2023-04-08 07:39:42--  https://www.dropbox.com/s/raw/fnpq3z4bcnoktiv/positive.csv\n",
      "Reusing existing connection to [www.dropbox.com]:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc244bfb605600a75d35e724cb42.dl.dropboxusercontent.com/cd/0/inline/B5wz6_heo-o97MJa6qvse-nks84Fqwx4gaFsEp-KDe7SMoX-JmwKvYOprVoDEg0VcN7kmArVhDniIitu4gT3l2ejD33kOrCKegxwvHeZUXh4cW1w3PN56UXzdD_AqxLYEamu2YhVw3-lRZWIzZ54nNfhP1PjGwqmMs1tqXs7dfPN5g/file# [following]\n",
      "--2023-04-08 07:39:43--  https://uc244bfb605600a75d35e724cb42.dl.dropboxusercontent.com/cd/0/inline/B5wz6_heo-o97MJa6qvse-nks84Fqwx4gaFsEp-KDe7SMoX-JmwKvYOprVoDEg0VcN7kmArVhDniIitu4gT3l2ejD33kOrCKegxwvHeZUXh4cW1w3PN56UXzdD_AqxLYEamu2YhVw3-lRZWIzZ54nNfhP1PjGwqmMs1tqXs7dfPN5g/file\n",
      "Resolving uc244bfb605600a75d35e724cb42.dl.dropboxusercontent.com (uc244bfb605600a75d35e724cb42.dl.dropboxusercontent.com)... 2620:100:6026:15::a27d:460f, 162.125.70.15\n",
      "Connecting to uc244bfb605600a75d35e724cb42.dl.dropboxusercontent.com (uc244bfb605600a75d35e724cb42.dl.dropboxusercontent.com)|2620:100:6026:15::a27d:460f|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26233379 (25M) [text/plain]\n",
      "Saving to: ‘positive.csv.3’\n",
      "\n",
      "positive.csv.3      100%[===================>]  25,02M  8,72MB/s    in 2,9s    \n",
      "\n",
      "2023-04-08 07:39:46 (8,72 MB/s) - ‘positive.csv.3’ saved [26233379/26233379]\n",
      "\n",
      "--2023-04-08 07:39:47--  https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 2620:100:6026:18::a27d:4612, 162.125.70.18\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|2620:100:6026:18::a27d:4612|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: /s/raw/r6u59ljhhjdg6j0/negative.csv [following]\n",
      "--2023-04-08 07:39:47--  https://www.dropbox.com/s/raw/r6u59ljhhjdg6j0/negative.csv\n",
      "Reusing existing connection to [www.dropbox.com]:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc3c8472e7d5ab329cbd2d7c6e67.dl.dropboxusercontent.com/cd/0/inline/B5xEMr4ZZZ2v79BYto-WkRLVqloyjCU3G2_jDRVCfCi93HQJ0xc6wC6e0jLD04gQdKzkauqa_ZXrQoH9sSInbhn2W99u6RD-Q_SiLpRM2NMeH0AVaLkZcXWYy1yGjqNRXqMZRWl5cYhRHvx4yRiE78PFglC82ZPgb0wP9KE1mREvqg/file# [following]\n",
      "--2023-04-08 07:39:47--  https://uc3c8472e7d5ab329cbd2d7c6e67.dl.dropboxusercontent.com/cd/0/inline/B5xEMr4ZZZ2v79BYto-WkRLVqloyjCU3G2_jDRVCfCi93HQJ0xc6wC6e0jLD04gQdKzkauqa_ZXrQoH9sSInbhn2W99u6RD-Q_SiLpRM2NMeH0AVaLkZcXWYy1yGjqNRXqMZRWl5cYhRHvx4yRiE78PFglC82ZPgb0wP9KE1mREvqg/file\n",
      "Resolving uc3c8472e7d5ab329cbd2d7c6e67.dl.dropboxusercontent.com (uc3c8472e7d5ab329cbd2d7c6e67.dl.dropboxusercontent.com)... 2620:100:6026:15::a27d:460f, 162.125.70.15\n",
      "Connecting to uc3c8472e7d5ab329cbd2d7c6e67.dl.dropboxusercontent.com (uc3c8472e7d5ab329cbd2d7c6e67.dl.dropboxusercontent.com)|2620:100:6026:15::a27d:460f|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 24450101 (23M) [text/plain]\n",
      "Saving to: ‘negative.csv.3’\n",
      "\n",
      "negative.csv.3      100%[===================>]  23,32M  8,70MB/s    in 2,7s    \n",
      "\n",
      "2023-04-08 07:39:50 (8,70 MB/s) - ‘negative.csv.3’ saved [24450101/24450101]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# если у вас линукс / мак / collab или ещё какая-то среда, в которой работает wget, можно так:\n",
    "!wget https://www.dropbox.com/s/fnpq3z4bcnoktiv/positive.csv\n",
    "!wget https://www.dropbox.com/s/r6u59ljhhjdg6j0/negative.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -U scikit-learn scipy matplotlib\n",
    "# !pip install pymystem3\n",
    "# !pip install pymorphy2\n",
    "# !pip install razdel\n",
    "# !pip install natasha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import time\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/gans/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# считываем данные и заполняем общий датасет\n",
    "positive = pd.read_csv('positive.csv', sep=';', usecols=[3], names=['text'])\n",
    "positive['label'] = ['positive'] * len(positive)\n",
    "negative = pd.read_csv('negative.csv', sep=';', usecols=[3], names=['text'])\n",
    "negative['label'] = ['negative'] * len(negative)\n",
    "# df = positive.append(negative)\n",
    "df = pd.concat([positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111918</th>\n",
       "      <td>Но не каждый хочет что то исправлять:( http://...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111919</th>\n",
       "      <td>скучаю так :-( только @taaannyaaa вправляет мо...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111920</th>\n",
       "      <td>Вот и в школу, в говно это идти уже надо(</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111921</th>\n",
       "      <td>RT @_Them__: @LisaBeroud Тауриэль, не грусти :...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111922</th>\n",
       "      <td>Такси везет меня на работу. Раздумываю приплат...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     label\n",
       "111918  Но не каждый хочет что то исправлять:( http://...  negative\n",
       "111919  скучаю так :-( только @taaannyaaa вправляет мо...  negative\n",
       "111920          Вот и в школу, в говно это идти уже надо(  negative\n",
       "111921  RT @_Them__: @LisaBeroud Тауриэль, не грусти :...  negative\n",
       "111922  Такси везет меня на работу. Раздумываю приплат...  negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df.text, df.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: классификация необработанных n-грамм\n",
    "\n",
    "### Векторизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # можно заменить на любимый классификатор\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что такое n-граммы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если',), ('б',), ('мне',), ('платили',), ('каждый',), ('раз',)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = 'Если б мне платили каждый раз'.split()\n",
    "list(ngrams(sent, 1)) # униграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б'),\n",
       " ('б', 'мне'),\n",
       " ('мне', 'платили'),\n",
       " ('платили', 'каждый'),\n",
       " ('каждый', 'раз')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 2)) # биграммы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Если', 'б', 'мне', 'платили', 'каждый'),\n",
       " ('б', 'мне', 'платили', 'каждый', 'раз')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ngrams(sent, 5)) # ... пентаграммы?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой способ извлечь фичи из текстовых данных -- векторизаторы: `CountVectorizer` и `TfidfVectorizer`\n",
    "\n",
    "Объект `CountVectorizer` делает простую вещь:\n",
    "* строит для каждого документа (каждой пришедшей ему строки) вектор размерности `n`, где `n` -- количество слов или n-грам во всём корпусе\n",
    "* заполняет каждый i-тый элемент количеством вхождений слова в данный документ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train) # bow -- bag of words (мешок слов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "ngram_range отвечает за то, какие n-граммы мы используем в качестве фичей:<br/>\n",
    "ngram_range=(1, 1) -- униграммы<br/>\n",
    "ngram_range=(3, 3) -- триграммы<br/>\n",
    "ngram_range=(1, 3) -- униграммы, биграммы и триграммы.\n",
    "\n",
    "В vec.vocabulary_ лежит словарь: мэппинг слов к их индексам:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reg_biryukova', 73089),\n",
       " ('портрет', 189659),\n",
       " ('который', 148626),\n",
       " ('рисовала', 203915),\n",
       " ('еще', 130765),\n",
       " ('летом', 152660),\n",
       " ('фотки', 231470),\n",
       " ('какой', 142787),\n",
       " ('то', 222059),\n",
       " ('вот', 114975)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.76      0.76     28322\n",
      "    positive       0.76      0.77      0.77     28387\n",
      "\n",
      "    accuracy                           0.77     56709\n",
      "   macro avg       0.77      0.77      0.77     56709\n",
      "weighted avg       0.77      0.77      0.77     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем сделать то же самое для триграмм:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.72      0.56     18169\n",
      "    positive       0.82      0.61      0.70     38540\n",
      "\n",
      "    accuracy                           0.65     56709\n",
      "   macro avg       0.64      0.66      0.63     56709\n",
      "weighted avg       0.71      0.65      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(3, 3))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      0.52      0.68     53458\n",
      "    positive       0.11      0.95      0.19      3251\n",
      "\n",
      "    accuracy                           0.55     56709\n",
      "   macro avg       0.55      0.74      0.44     56709\n",
      "weighted avg       0.94      0.55      0.66     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(5, 5))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(как вы думаете, почему в результатах теперь такой разброс по сравнению с униграммами?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответ**  \n",
    "С ростом n-грамм, размер словаря увеличился, вероятность встретить определённое сочетание из трёх слов меньше, чем вероятность встретить одно какое-то слово, из-за этого увеличивается разряженность дынных и следовательно модель начинает переобучаться, становится менее устойчивая к новым данным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF векторизация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TfidfVectorizer` делает то же, что и `CountVectorizer`, но в качестве значений – tf-idf каждого слова.\n",
    "\n",
    "Как считается tf-idf:\n",
    "\n",
    "TF (term frequency) – относительная частотность слова в документе:\n",
    "$$ TF(t,d) = \\frac{n_t}{\\sum_k n_k} $$\n",
    "\n",
    "`t` -- слово (term), `d` -- документ, $n_t$ -- количество вхождений слова, $n_k$ -- количество вхождений остальных слов\n",
    "\n",
    "IDF (inverse document frequency) – обратная частота документов, в которых есть это слово:\n",
    "$$ IDF(t, D) = \\mbox{log} \\frac{|D|}{|{d : t \\in d}|} $$\n",
    "\n",
    "`t` -- слово (term), `D` -- коллекция документов\n",
    "\n",
    "Перемножаем их:\n",
    "$$TFIDF_(t,d,D) = TF(t,d) \\times IDF(i, D)$$\n",
    "\n",
    "Сакральный смысл – если слово часто встречается в одном документе, но в целом по корпусу встречается в небольшом \n",
    "количестве документов, у него высокий TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.73      0.77      0.75     26782\n",
      "    positive       0.78      0.75      0.77     29927\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этот раз получилось хуже :( Вернёмся к CountVectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно оценить взаимосвязь слов в корпусе и понять, какие биграммы наиболее часто встречаются в тексте. Для этого можно использовать метрику PMI (Pointwise Mutual Information) - поточечная взаимная информация. Метрика PMI для двух слов вычисляется по формуле:\n",
    "\n",
    "$$pmi(x; y) = log \\frac{p(x,y)}{p(x)p(y)} $$\n",
    "\n",
    "Здесь p(y|x) - вероятность встретить слово $y$ после $x$, $p(y)$ - вероятность встретить слово $y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим важность биграмм в нашем обучающем корпусе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.corpus.reader.util.StreamBackedCorpusView'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package genesis to /home/gans/nltk_data...\n",
      "[nltk_data]   Package genesis is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('+1239', '728'), ('+375292377543', 'отправьте'), ('+375447167151', 'звоги'), ('+Никита', '=полностью'), ('+живіт', 'болить.ну'), ('+погода', 'крутая='), (',4', 'запирайте'), (',Дела', 'рез'), ('-/////', 'прбрм-прбрм'), ('-15-16', '-котейка'), ('-163', '-КРАСНЫЙ'), ('-165', '-СИНИЙ'), ('-700', 'рублей.-А'), ('-АХАХАХАХХАХАХАХАХАХХА', '-АХАХАХХАХАХАХАХАХ'), ('-Алина', '-Синие'), ('-Аха', 'спетросянил'), ('-ВАХАХАХА', 'СТИПЕНДИЯ'), ('-ВСЕМ', 'СПОКОЙНЫХ'), ('-Весело', 'кншн:3'), ('-Восьмигрудый', 'трипи'), ('-Время', 'эмокора'), ('-Выздоравливай', 'педрилк'), ('-ГНИДОТА', '-Над'), ('-Д-Д-Д-Д-Д-Д-ДРОП', 'ЗЭ'), ('-ДОВАЙТИ', 'АЛДСКУЛ'), ('-Дирол', 'Сенсес'), ('-ЖРАТЬ', 'БАРАНКИ'), ('-ЗАШЛА', 'ОДЕЛА'), ('-Защитано', '-ес'), ('-Зелено-карие', '-Киллджой'), ('-КРАСНЫЙ', '-ЧЕРНЫЕ'), ('-Киллджой', '-Котик'), ('-Лера', 'Синим'), ('-МНОГО', 'СЛИВОК'), ('-Маладец', '-Лол'), ('-Мамаааа', 'поправь'), ('-НА', 'РЕАЛЬНЫХ'), ('-НАЧИНАЕТ', 'БЕСИТЬ'), ('-ОЗВУЧИВАТЕЛЬ', 'МУЛЬТИКОВ'), ('-Олесь', '-Пошёл'), ('-Песня', 'грусная='), ('-Поэзия', 'заключает'), ('-ПриФетиГг', 'СолНыСко='), ('-Рыбу', 'соленую'), ('-СИНИЙ', '-БЕЛЫЕ'), ('-Серые', '-НЕМЕЦКИЕ'), ('-Ти', 'кантужена'), ('-ФОН', '-БИО'), ('-Филл', '-познакомились'), ('-ШАПКА', '-ФОН'), ('-ЮН', '-ЮП'), ('-ЮП', '-ШАПКА'), ('-аас', 'бусдыг'), ('-анал', '-абстиненция'), ('-анатолий', 'николаевич'), ('-белый', '-15-16'), ('-бляя', 'хммммммм'), ('-водичку', 'лью'), ('-возвышенная', 'местность'), ('-г', 'үзээ'), ('-гoop', 'Хакүхо'), ('-говорит', 'одноногий'), ('-дайте', 'winston'), ('-иногда', '.Ностальгирую'), ('-крутенько', '-выйду'), ('-кучи', 'мутики'), ('-ладно', '-АХАХАХАХХАХАХАХАХАХХА'), ('-мега', 'шизофреничная'), ('-место', '-кровать'), ('-напиши', '-нит'), ('-наш', 'класс^^'), ('-новый', 'молодежный'), ('-пиздишь', '-отвечаю'), ('-попробуй', 'помедитировать'), ('-раз', 'плёткой'), ('-распускаю', 'волосы-'), ('-розовое', 'Нарри'), ('-руу', 'орох'), ('-рцензию', 'десятилетия'), ('-рүү', 'мэншндсэн'), ('-спрашивает', 'жена.-У'), ('-удивительная', 'штука.Его'), ('-указуказуказуказуа', '-материшся'), ('-хаски', '-розовое'), ('-хуи', 'сосешь'), ('-цитирую', 'гастролога'), ('-цытата', 'Шимы'), ('-шапку', '-фон'), ('-ынхаа', 'кодын'), ('-юн', '-юп'), ('-юп', '-шапку'), ('-языком', 'владеешь'), ('.NET', 'языки.'), ('.Вы', 'ахуеете'), ('.Прозвучало', 'неубедительно.Учитель'), ('.Спасибо', 'Бердянску'), ('.Хочу', 'миксануть'), ('.ШТА', 'БУДИШЬ'), ('.всё', 'неполноценность.я'), ('.выражаешься', '.то')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import collocations \n",
    "nltk.download('genesis')\n",
    "\n",
    "print(type(nltk.corpus.genesis.words('english-web.txt')))\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "# bigram_finder.apply_freq_filter(5)\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_documents([nltk.word_tokenize(x) for x in x_train])\n",
    "bigrams = bigram_finder.nbest(bigram_measures.pmi, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассмотреть другие метрики оценки важности биграмм, например, метрику правдоподобия (подробнее про вычисление метрики можно посмотреть [здесь (пункт 5.3.4)](http://www.corpus.unam.mx/cursoenah/ManningSchutze_1999_FoundationsofStatisticalNaturalLanguageProcessing.pdf):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('(', '('), ('RT', '@'), (')', ')'), ('http', ':'), ('!', '!'), (':', 'D'), ('у', 'меня'), (':', '('), (',', 'а'), (',', 'что'), (',', 'но'), (')', 'http'), ('*', '*'), ('у', 'нас'), (':', ')'), ('(', ','), ('не', 'могу'), (':', '-'), (',', '('), (',', ')'), ('?', '?'), (')', ','), (',', ':'), ('@', '('), (',', ','), (':', ','), ('(', ':'), ('@', ','), ('&', 'lt'), ('со', 'мной'), ('@', ':'), (':', ':'), ('(', '@'), (';', ')'), ('новый', 'год'), ('gt', ';'), ('не', 'знаю'), (')', ':'), (':', '*'), (',', '@'), ('а', 'я'), ('@', '@'), (',', 'когда'), ('У', 'меня'), ('потому', 'что'), ('lt', ';'), ('сих', 'пор'), ('у', 'тебя'), ('&', 'gt'), (';', '('), ('с', 'тобой'), ('все', 'равно'), (',', 'как'), ('в', 'школу'), ('ничего', 'не'), ('(', 'http'), (')', '@'), ('&', 'amp'), ('Как', 'же'), ('-', ')'), (',', 'я'), (':', 'DD'), ('самом', 'деле'), ('Доброе', 'утро'), ('я', 'не'), ('не', '('), ('не', ')'), ('--', '--'), ('об', 'этом'), ('что', 'я'), ('amp', ';'), ('до', 'сих'), (',', 'чтобы'), (',', '!'), ('(', '!'), ('как', 'же'), ('D', 'http'), ('никто', 'не'), ('=', ')'), ('не', ':'), ('!', ','), ('и', '('), (':', '!'), ('с', 'кем'), ('.', 'А'), ('?', '—'), (':', '|'), ('а', 'потом'), ('Новый', 'Год'), ('и', ')'), ('никогда', 'не'), (',', '.'), ('.', 'Но'), ('.', ','), ('#', 'євромайдан'), ('@', 'не'), ('не', '@'), ('“', '@'), ('в', 'школе'), ('@', '!')]\n"
     ]
    }
   ],
   "source": [
    "bigrams = bigram_finder.nbest(bigram_measures.likelihood_ratio, 100)\n",
    "print(bigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно заметить, немаловажную роль в текстах занимает пунктуация."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стоп-слова и пунктуация\n",
    "\n",
    "*Стоп-слова* -- это слова, которые часто встречаются практически в любом тексте и ничего интересного не говорят о конретном документе, то есть играют роль шума. Поэтому их принято убирать. По той же причине убирают и пунктуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/gans/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# у вас здесь, вероятно, выскочит ошибка и надо будет загрузить стоп слова (в тексте ошибки написано, как)\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "print(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "noise = stopwords.words('russian') + list(punctuation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "В векторизаторах за стоп-слова, логичным образом, отвечает аргумент `stop_words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29234\n",
      "    positive       0.76      0.80      0.78     27475\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация\n",
    "\n",
    "Лемматизация – это сведение разных форм одного слова к начальной форме – *лемме*. Почему это хорошо?\n",
    "* Во-первых, мы хотим рассматривать как отдельную фичу каждое *слово*, а не каждую его отдельную форму.\n",
    "* Во-вторых, некоторые стоп-слова стоят только в начальной форме, и без лематизации выкидываем мы только её.\n",
    "\n",
    "Для русского есть два хороших лемматизатора: mystem и pymorphy:\n",
    "\n",
    "### [Mystem](https://tech.yandex.ru/mystem/)\n",
    "Как с ним работать:\n",
    "* можно скачать mystem и запускать [из терминала с разными параметрами](https://tech.yandex.ru/mystem/doc/)\n",
    "* [pymystem3](https://pythonhosted.org/pymystem3/pymystem3.html) - обертка для питона, работает медленнее, но это удобно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-08 07:42:42--  http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
      "Resolving download.cdn.yandex.net (download.cdn.yandex.net)... 2a02:6b8::231, 5.45.205.241, 5.45.205.244, ...\n",
      "Connecting to download.cdn.yandex.net (download.cdn.yandex.net)|2a02:6b8::231|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: http://cachev2-m9-5.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=3 [following]\n",
      "--2023-04-08 07:42:42--  http://cachev2-m9-5.cdn.yandex.net/download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz?lid=3\n",
      "Resolving cachev2-m9-5.cdn.yandex.net (cachev2-m9-5.cdn.yandex.net)... 2a02:6b8:c35:2:0:562:0:8, 37.9.111.163\n",
      "Connecting to cachev2-m9-5.cdn.yandex.net (cachev2-m9-5.cdn.yandex.net)|2a02:6b8:c35:2:0:562:0:8|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16457938 (16M) [application/octet-stream]\n",
      "Saving to: ‘mystem-3.0-linux3.1-64bit.tar.gz.1’\n",
      "\n",
      "mystem-3.0-linux3.1 100%[===================>]  15,70M  7,17MB/s    in 2,2s    \n",
      "\n",
      "2023-04-08 07:42:44 (7,17 MB/s) - ‘mystem-3.0-linux3.1-64bit.tar.gz.1’ saved [16457938/16457938]\n",
      "\n",
      "mystem\n",
      "cp: cannot create regular file '/bin/mystem': Permission denied\n"
     ]
    }
   ],
   "source": [
    "!wget http://download.cdn.yandex.net/mystem/mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!tar -xvf mystem-3.0-linux3.1-64bit.tar.gz\n",
    "!cp mystem /bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mystem_analyzer = Mystem()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы инициализировали Mystem c дефолтными параметрами. А вообще параметры есть такие:\n",
    "* mystem_bin - путь к `mystem`, если их несколько\n",
    "* grammar_info - нужна ли грамматическая информация или только леммы (по дефолту нужна)\n",
    "* disambiguation - нужно ли снятие омонимии - дизамбигуация (по дефолту нужна)\n",
    "* entire_input - нужно ли сохранять в выводе все (пробелы всякие, например), или можно выкинуть (по дефолту оставляется все)\n",
    "\n",
    "Методы Mystem принимают строку, токенизатор вшит внутри. Можно, конечно, и пословно анализировать, но тогда он не сможет учитывать контекст.\n",
    "\n",
    "Можно просто лемматизировать текст:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "example = 'Но не каждый хочет что-то исправлять :(\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['но', ' ', 'не', ' ', 'каждый', ' ', 'хотеть', ' ', 'что-то', ' ', 'исправлять', ' :(\\n']\n"
     ]
    }
   ],
   "source": [
    "print(mystem_analyzer.lemmatize(example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно получить грамматическую информацию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'analysis': [{'lex': 'но', 'wt': 0.9998906299, 'gr': 'CONJ='}],\n",
       "  'text': 'Но'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'не', 'wt': 1, 'gr': 'PART='}], 'text': 'не'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'каждый',\n",
       "    'wt': 0.9985975799,\n",
       "    'gr': 'APRO=(вин,ед,муж,неод|им,ед,муж)'}],\n",
       "  'text': 'каждый'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'хотеть',\n",
       "    'wt': 1,\n",
       "    'gr': 'V,несов,пе=непрош,ед,изъяв,3-л'}],\n",
       "  'text': 'хочет'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'что-то', 'wt': 1, 'gr': 'SPRO,ед,сред,неод=(вин|им)'}],\n",
       "  'text': 'что-то'},\n",
       " {'text': ' '},\n",
       " {'analysis': [{'lex': 'исправлять', 'wt': 1, 'gr': 'V,пе=инф,несов'}],\n",
       "  'text': 'исправлять'},\n",
       " {'text': ' :(\\n'}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mystem_analyzer.analyze(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте теперь используем лемматизатор майстема в качестве токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def my_preproc(text):\n",
    "    text = re.sub('[{}]'.format(punctuation), '', text)\n",
    "    text = mystem_analyzer.lemmatize(text)\n",
    "    return [word for word in text if word not in stopwords.words('russian') + [' ', '\\n']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.74      0.76     29292\n",
      "    positive       0.74      0.77      0.76     27417\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.76      0.76     56709\n",
      "weighted avg       0.76      0.76      0.76     56709\n",
      "\n",
      "CPU times: user 5min 49s, sys: 1min 19s, total: 7min 9s\n",
      "Wall time: 7min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=my_preproc)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Pymorphy](http://pymorphy2.readthedocs.io/en/latest/)\n",
    "Это модуль на питоне, довольно быстрый и с кучей функций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pymorphy2 import MorphAnalyzer\n",
    "pymorphy2_analyzer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pymorphy2 работает с отдельными словами. Если дать ему на вход предложение - он его просто не лемматизирует, т.к. не понимает"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='платили', tag=OpencorporaTag('VERB,impf,tran plur,past,indc'), normal_form='платить', score=1.0, methods_stack=((DictionaryAnalyzer(), 'платили', 2472, 10),))]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana = pymorphy2_analyzer.parse(sent[3])\n",
    "ana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'платить'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ana[0].normal_form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Natasha](https://github.com/natasha/)\n",
    "\n",
    "В библиотеке natasha реализовано множество полезных библиотек для русского языка: разбиение на токены и предложения, русскоязычные word embeddings, морфологический, синтаксический анализ, лемматизация, извлечение именованных сущностей и т.д. Модуль библиотеки Razdel, основанный на правилах, предназначен для разбиения текста на токены и предложения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Substring(0, 13, 'Кружка-термос'),\n",
       " Substring(14, 16, 'на'),\n",
       " Substring(17, 20, '0.5'),\n",
       " Substring(20, 21, 'л'),\n",
       " Substring(22, 23, '('),\n",
       " Substring(23, 28, '50/64'),\n",
       " Substring(29, 32, 'см³'),\n",
       " Substring(32, 33, ','),\n",
       " Substring(34, 37, '516'),\n",
       " Substring(37, 38, ';'),\n",
       " Substring(38, 41, '...'),\n",
       " Substring(41, 42, ')')]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from razdel import tokenize\n",
    "\n",
    "tokens = list(tokenize('Кружка-термос на 0.5л (50/64 см³, 516;...)'))\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Кружка-термос',\n",
       " 'на',\n",
       " '0.5',\n",
       " 'л',\n",
       " '(',\n",
       " '50/64',\n",
       " 'см³',\n",
       " ',',\n",
       " '516',\n",
       " ';',\n",
       " '...',\n",
       " ')']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[_.text for _ in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью библиотеки natasha можно также лемматизировать тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from natasha import Doc, MorphVocab, Segmenter, NewsEmbedding, NewsMorphTagger\n",
    "\n",
    "segmenter = Segmenter()\n",
    "morph_vocab = MorphVocab()\n",
    "emb = NewsEmbedding()\n",
    "morph_tagger = NewsMorphTagger(emb)\n",
    "\n",
    "def natasha_lemmatize(text):\n",
    "  doc = Doc(text)\n",
    "  doc.segment(segmenter)\n",
    "  doc.tag_morph(morph_tagger)\n",
    "  for token in doc.tokens:\n",
    "    token.lemmatize(morph_vocab)\n",
    "  return {_.text: _.lemma for _ in doc.tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Посол': 'посол',\n",
       " 'Израиля': 'израиль',\n",
       " 'на': 'на',\n",
       " 'Украине': 'украина',\n",
       " 'Йоэль': 'йоэль',\n",
       " 'Лион': 'лион',\n",
       " 'признался': 'признаться',\n",
       " ',': ',',\n",
       " 'что': 'что',\n",
       " 'пришел': 'прийти',\n",
       " 'в': 'в',\n",
       " 'шок': 'шок',\n",
       " 'узнав': 'узнать',\n",
       " 'о': 'о',\n",
       " 'решении': 'решение',\n",
       " 'властей': 'власть',\n",
       " 'Львовской': 'львовский',\n",
       " 'области': 'область',\n",
       " 'объявить': 'объявить',\n",
       " '2019': '2019',\n",
       " 'год': 'год',\n",
       " 'годом': 'год',\n",
       " 'лидера': 'лидер',\n",
       " 'запрещенной': 'запретить',\n",
       " 'России': 'россия',\n",
       " 'Организации': 'организация',\n",
       " 'украинских': 'украинский',\n",
       " 'националистов': 'националист',\n",
       " '(': '(',\n",
       " 'ОУН': 'оун',\n",
       " ')': ')',\n",
       " 'Степана': 'степан',\n",
       " 'Бандеры': 'бандера',\n",
       " '.': '.',\n",
       " 'Свое': 'свой',\n",
       " 'заявление': 'заявление',\n",
       " 'он': 'он',\n",
       " 'разместил': 'разместить',\n",
       " 'Twitter': 'twitter',\n",
       " '«': '«',\n",
       " 'Я': 'я',\n",
       " 'не': 'не',\n",
       " 'могу': 'мочь',\n",
       " 'понять': 'понять',\n",
       " 'как': 'как',\n",
       " 'прославление': 'прославление',\n",
       " 'тех': 'тот',\n",
       " 'кто': 'кто',\n",
       " 'непосредственно': 'непосредственно',\n",
       " 'принимал': 'принимать',\n",
       " 'участие': 'участие',\n",
       " 'ужасных': 'ужасный',\n",
       " 'антисемитских': 'антисемитский',\n",
       " 'преступлениях': 'преступление',\n",
       " 'помогает': 'помогать',\n",
       " 'бороться': 'бороться',\n",
       " 'с': 'с',\n",
       " 'антисемитизмом': 'антисемитизм',\n",
       " 'и': 'и',\n",
       " 'ксенофобией': 'ксенофобия',\n",
       " 'Украина': 'украина',\n",
       " 'должна': 'должный',\n",
       " 'забывать': 'забывать',\n",
       " 'совершенных': 'совершить',\n",
       " 'против': 'против',\n",
       " 'евреев': 'еврей',\n",
       " 'никоим': 'никой',\n",
       " 'образом': 'образ',\n",
       " 'отмечать': 'отмечать',\n",
       " 'их': 'они',\n",
       " 'через': 'через',\n",
       " 'почитание': 'почитание',\n",
       " 'исполнителей': 'исполнитель',\n",
       " '»': '»',\n",
       " '—': '—',\n",
       " 'написал': 'написать',\n",
       " 'дипломат': 'дипломат',\n",
       " '11': '11',\n",
       " 'декабря': 'декабрь',\n",
       " 'Львовский': 'львовский',\n",
       " 'областной': 'областной',\n",
       " 'совет': 'совет',\n",
       " 'принял': 'принять',\n",
       " 'решение': 'решение',\n",
       " 'провозгласить': 'провозгласить',\n",
       " 'регионе': 'регион',\n",
       " 'связи': 'связь',\n",
       " 'празднованием': 'празднование',\n",
       " '110-летия': '110-летие',\n",
       " 'со': 'с',\n",
       " 'дня': 'день',\n",
       " 'рождения': 'рождение',\n",
       " 'Бандера': 'бандера',\n",
       " 'родился': 'родиться',\n",
       " '1': '1',\n",
       " 'января': 'январь',\n",
       " '1909': '1909',\n",
       " 'года': 'год',\n",
       " 'В': 'в',\n",
       " 'июле': 'июль',\n",
       " 'аналогичное': 'аналогичный',\n",
       " 'Житомирский': 'житомирский',\n",
       " 'начале': 'начало',\n",
       " 'месяца': 'месяц',\n",
       " 'предложением': 'предложение',\n",
       " 'к': 'к',\n",
       " 'президенту': 'президент',\n",
       " 'страны': 'страна',\n",
       " 'Петру': 'петр',\n",
       " 'Порошенко': 'порошенко',\n",
       " 'вернуть': 'вернуть',\n",
       " 'Бандере': 'бандера',\n",
       " 'звание': 'звание',\n",
       " 'Героя': 'герой',\n",
       " 'Украины': 'украина',\n",
       " 'обратились': 'обратиться',\n",
       " 'депутаты': 'депутат',\n",
       " 'Верховной': 'верховный',\n",
       " 'Рады': 'рада',\n",
       " 'Парламентарии': 'парламентарий',\n",
       " 'уверены': 'уверить',\n",
       " 'признание': 'признание',\n",
       " 'национальным': 'национальный',\n",
       " 'героем': 'герой',\n",
       " 'поможет': 'помочь',\n",
       " 'борьбе': 'борьба',\n",
       " 'подрывной': 'подрывной',\n",
       " 'деятельностью': 'деятельность',\n",
       " 'информационном': 'информационный',\n",
       " 'поле': 'поле',\n",
       " 'а': 'а',\n",
       " 'также': 'также',\n",
       " 'остановит': 'остановить',\n",
       " 'распространение': 'распространение',\n",
       " 'мифов': 'миф',\n",
       " 'созданных': 'создать',\n",
       " 'российской': 'российский',\n",
       " 'пропагандой': 'пропаганда',\n",
       " 'Степан': 'степан',\n",
       " '1909-1959': '1909-1959',\n",
       " 'был': 'быть',\n",
       " 'одним': 'один',\n",
       " 'из': 'из',\n",
       " 'лидеров': 'лидер',\n",
       " 'выступающей': 'выступать',\n",
       " 'за': 'за',\n",
       " 'создание': 'создание',\n",
       " 'независимого': 'независимый',\n",
       " 'государства': 'государство',\n",
       " 'территориях': 'территория',\n",
       " 'украиноязычным': 'украиноязычный',\n",
       " 'населением': 'население',\n",
       " '2010': '2010',\n",
       " 'году': 'год',\n",
       " 'период': 'период',\n",
       " 'президентства': 'президентство',\n",
       " 'Виктора': 'виктор',\n",
       " 'Ющенко': 'ющенко',\n",
       " 'посмертно': 'посмертно',\n",
       " 'признан': 'признать',\n",
       " 'Героем': 'герой',\n",
       " 'однако': 'однако',\n",
       " 'впоследствии': 'впоследствии',\n",
       " 'это': 'это',\n",
       " 'было': 'быть',\n",
       " 'отменено': 'отменить',\n",
       " 'судом': 'суд'}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Посол Израиля на Украине Йоэль Лион признался, что пришел в шок, узнав о решении властей Львовской области объявить 2019 год годом лидера запрещенной в России Организации украинских националистов (ОУН) Степана Бандеры. Свое заявление он разместил в Twitter. «Я не могу понять, как прославление тех, кто непосредственно принимал участие в ужасных антисемитских преступлениях, помогает бороться с антисемитизмом и ксенофобией. Украина не должна забывать о преступлениях, совершенных против украинских евреев, и никоим образом не отмечать их через почитание их исполнителей», — написал дипломат. 11 декабря Львовский областной совет принял решение провозгласить 2019 год в регионе годом Степана Бандеры в связи с празднованием 110-летия со дня рождения лидера ОУН (Бандера родился 1 января 1909 года). В июле аналогичное решение принял Житомирский областной совет. В начале месяца с предложением к президенту страны Петру Порошенко вернуть Бандере звание Героя Украины обратились депутаты Верховной Рады. Парламентарии уверены, что признание Бандеры национальным героем поможет в борьбе с подрывной деятельностью против Украины в информационном поле, а также остановит «распространение мифов, созданных российской пропагандой». Степан Бандера (1909-1959) был одним из лидеров Организации украинских националистов, выступающей за создание независимого государства на территориях с украиноязычным населением. В 2010 году в период президентства Виктора Ющенко Бандера был посмертно признан Героем Украины, однако впоследствии это решение было отменено судом. '\n",
    "\n",
    "natasha_lemmatize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mystem vs. pymorphy vs. natasha\n",
    "\n",
    "1) *Мы надеемся, что вы пользуетесь линуксом*, но mystem работает невероятно медленно под windows на больших текстах.\n",
    "\n",
    "2) *Снятие омонимии*. Mystem умеет снимать омонимию по контексту (хотя не всегда преуспевает), pymorphy2 берет на вход одно слово и соответственно вообще не умеет дизамбигуировать по контексту, natasha с этим тоже не справляется успешно:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "homonym1 = 'За время обучения я прослушал больше сорока курсов.'\n",
    "homonym2 = 'Сорока своровала блестящее украшение со стола.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analysis': [{'lex': 'сорок', 'wt': 0.8710292664, 'gr': 'NUM=(пр|дат|род|твор)'}], 'text': 'сорока'}\n",
      "{'analysis': [{'lex': 'сорока', 'wt': 0.1210970041, 'gr': 'S,жен,од=им,ед'}], 'text': 'Сорока'}\n"
     ]
    }
   ],
   "source": [
    "mystem_analyzer = Mystem() # инициализирую объект с дефолтными параметрами\n",
    "\n",
    "print(mystem_analyzer.analyze(homonym1)[-5])\n",
    "print(mystem_analyzer.analyze(homonym2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'За': 'за', 'время': 'время', 'обучения': 'обучение', 'я': 'я', 'прослушал': 'прослушать', 'больше': 'большой', 'сорока': 'сорок', 'курсов': 'курс', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Сорока': 'сорок', 'своровала': 'своровать', 'блестящее': 'блестящий', 'украшение': 'украшение', 'со': 'с', 'стола': 'стол', '.': '.'}\n"
     ]
    }
   ],
   "source": [
    "print(natasha_lemmatize(homonym2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Словарь, закон Ципфа и закон Хипса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Ципфа -- эмпирическая закономерность: если все слова корпуса текста упорядочить по убыванию частоты их использования, то частота n-го слова в таком списке окажется приблизительно обратно пропорциональной его порядковому номеру n. Иными словами, частотность слов убывает очень быстро."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2870536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['first_timee', 'хоть', 'я', 'и', 'школота', 'но', 'поверь', 'у', 'нас', 'то']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in df.text for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 69472),\n",
       " ('и', 55166),\n",
       " ('в', 52902),\n",
       " ('я', 52818),\n",
       " ('RT', 38070),\n",
       " ('на', 35759),\n",
       " ('http', 32998),\n",
       " ('что', 31541),\n",
       " ('с', 27217),\n",
       " ('а', 26860)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjkAAAGdCAYAAADwjmIIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABJdUlEQVR4nO3de3xTdZ4//lfu6S0pbWlDaQsoSC2UW5EaRV3GLlE7F4R1kWGUQdSFKQ7QGVBWBccZrT9cR3EGcdAdcb+jAp1VVy7C1CIwSrkVKuVWUMCWS1pK26TXpEk+vz9KDkRAe0tPkr6ej0cekpx3Tt4545CXn/M5n6MQQggQERERhRil3A0QERER+QNDDhEREYUkhhwiIiIKSQw5REREFJIYcoiIiCgkMeQQERFRSGLIISIiopDEkENEREQhSS13A3LyeDw4d+4coqKioFAo5G6HiIiI2kEIgfr6eiQmJkKpvP54Ta8OOefOnUNycrLcbRAREVEnVFRUICkp6brbe3XIiYqKAtB2kAwGg8zdEBERUXvY7XYkJydLv+PX06tDjvcUlcFgYMghIiIKMj801YQTj4mIiCgkMeQQERFRSGLIISIiopDEkENEREQhiSGHiIiIQhJDDhEREYUkhhwiIiIKSR0KOQMHDoRCobjqkZOTAwBoaWlBTk4OYmNjERkZiSlTpqCystJnH+Xl5cjOzkZ4eDji4+OxcOFCuFwun5pt27ZhzJgx0Ol0GDx4MFavXn1VLytWrMDAgQOh1+uRmZmJPXv2dPCrExERUSjrUMjZu3cvzp8/Lz0KCgoAAA888AAAYMGCBVi/fj3y8/Oxfft2nDt3DpMnT5be73a7kZ2dDafTiZ07d+Ldd9/F6tWrsWTJEqnm1KlTyM7OxoQJE1BSUoL58+fj0UcfxZYtW6SatWvXIjc3F0uXLsX+/fsxcuRIWCwWVFVVdelgEBERUQgRXTBv3jxx4403Co/HI+rq6oRGoxH5+fnS9qNHjwoAoqioSAghxKZNm4RSqRRWq1WqWblypTAYDMLhcAghhFi0aJEYNmyYz+dMnTpVWCwW6fm4ceNETk6O9NztdovExESRl5fXof5tNpsAIGw2W4feR0RERPJp7+93p+fkOJ1O/O1vf8MjjzwChUKB4uJitLa2IisrS6pJTU1FSkoKioqKAABFRUVIT09HQkKCVGOxWGC323H48GGp5sp9eGu8+3A6nSguLvapUSqVyMrKkmqux+FwwG63+zyIiIgoNHU65Hz88ceoq6vDL3/5SwCA1WqFVqtFdHS0T11CQgKsVqtUc2XA8W73bvu+GrvdjubmZlRXV8Ptdl+zxruP68nLy4PRaJQevAM5ERFR6Op0yPnv//5v3HvvvUhMTOzOfvxq8eLFsNls0qOiosIvn/NqwXH850elqG5w+GX/RERE9MM6dRfyb7/9Fp999hk+/PBD6TWTyQSn04m6ujqf0ZzKykqYTCap5rtXQXmvvrqy5rtXZFVWVsJgMCAsLAwqlQoqleqaNd59XI9Op4NOp+vYl+2ED/aUo6regemZKYiL9P/nERER0dU6NZLzzjvvID4+HtnZ2dJrGRkZ0Gg0KCwslF4rKytDeXk5zGYzAMBsNqO0tNTnKqiCggIYDAakpaVJNVfuw1vj3YdWq0VGRoZPjcfjQWFhoVQjN0OYBgBgb3b9QCURERH5S4dHcjweD9555x3MmDEDavXltxuNRsyaNQu5ubmIiYmBwWDAE088AbPZjFtvvRUAMHHiRKSlpeGhhx7CsmXLYLVa8cwzzyAnJ0caYZk9ezb+/Oc/Y9GiRXjkkUewdetWrFu3Dhs3bpQ+Kzc3FzNmzMDYsWMxbtw4vPbaa2hsbMTMmTO7ejy6hUHfdlzsLa0yd0JERNR7dTjkfPbZZygvL8cjjzxy1bZXX30VSqUSU6ZMgcPhgMViwRtvvCFtV6lU2LBhA+bMmQOz2YyIiAjMmDEDzz//vFQzaNAgbNy4EQsWLMDy5cuRlJSEt99+GxaLRaqZOnUqLly4gCVLlsBqtWLUqFHYvHnzVZOR5XJ5JIchh4iISC4KIYSQuwm52O12GI1G2Gw2GAyGbtvvrz84gE++Oodnsm/Go3fc0G37JSIiovb/fvPeVX5gCPOeruKcHCIiIrkw5PiBkaeriIiIZMeQ4wcG/aWQw4nHREREsmHI8QNeQk5ERCQ/hhw/kEZyeLqKiIhINgw5fnB54jFDDhERkVwYcvyAE4+JiIjkx5DjB5cnHnNODhERkVwYcvzAO/G4weGCy+2RuRsiIqLeiSHHD6L0l++WUc/RHCIiIlkw5PiBRqVEuFYFgJOPiYiI5MKQ4ydGrpVDREQkK4YcP+Gqx0RERPJiyPETaa0cXkZOREQkC4YcP/GO5NgYcoiIiGTBkOMn0v2reLqKiIhIFgw5fmLQe09XceIxERGRHBhy/MTIkRwiIiJZMeT4iYH3ryIiIpIVQ46fcOIxERGRvBhy/ES6hJy3dSAiIpIFQ46fSIsBciSHiIhIFgw5fsJLyImIiOTFkOMnvHcVERGRvBhy/MR7uqq51Q2nyyNzN0RERL0PQ46fRF5aDBDgKSsiIiI5MOT4iUqpQJSON+kkIiKSC0OOH12efMx5OURERD2NIcePuOoxERGRfBhy/Mh7k06uekxERNTzGHL8iGvlEBERyYchx48ur3rMOTlEREQ9jSHHjy7fv4ojOURERD2NIcePjJx4TEREJBuGHD/ynq7ixGMiIqKex5DjR1wnh4iISD4MOX7kvYScp6uIiIh6HkOOH/ESciIiIvkw5PjR5YnHPF1FRETU0zoccs6ePYtf/OIXiI2NRVhYGNLT07Fv3z5puxACS5YsQb9+/RAWFoasrCycOHHCZx81NTWYPn06DAYDoqOjMWvWLDQ0NPjUHDx4EHfccQf0ej2Sk5OxbNmyq3rJz89Hamoq9Ho90tPTsWnTpo5+Hb/iSA4REZF8OhRyamtrcfvtt0Oj0eDTTz/FkSNH8Morr6BPnz5SzbJly/D666/jzTffxO7duxEREQGLxYKWlhapZvr06Th8+DAKCgqwYcMG7NixA48//ri03W63Y+LEiRgwYACKi4vx8ssv47nnnsOqVaukmp07d2LatGmYNWsWDhw4gEmTJmHSpEk4dOhQV45Ht/LOyXG6PGhpdcvcDRERUS8jOuDJJ58U48ePv+52j8cjTCaTePnll6XX6urqhE6nEx988IEQQogjR44IAGLv3r1SzaeffioUCoU4e/asEEKIN954Q/Tp00c4HA6fzx46dKj0/N///d9Fdna2z+dnZmaK//iP/2j397HZbAKAsNls7X5PR7jdHjHoqQ1iwJMbRKWt2S+fQURE1Nu09/e7QyM5n3zyCcaOHYsHHngA8fHxGD16NN566y1p+6lTp2C1WpGVlSW9ZjQakZmZiaKiIgBAUVERoqOjMXbsWKkmKysLSqUSu3fvlmruvPNOaLVaqcZisaCsrAy1tbVSzZWf463xfs61OBwO2O12n4c/KZUKROl5yoqIiEgOHQo5J0+exMqVKzFkyBBs2bIFc+bMwa9//Wu8++67AACr1QoASEhI8HlfQkKCtM1qtSI+Pt5nu1qtRkxMjE/NtfZx5Wdcr8a7/Vry8vJgNBqlR3Jycke+fqd4b+1g4+RjIiKiHtWhkOPxeDBmzBi8+OKLGD16NB5//HE89thjePPNN/3VX7davHgxbDab9KioqPD7Zxo5+ZiIiEgWHQo5/fr1Q1pams9rN998M8rLywEAJpMJAFBZWelTU1lZKW0zmUyoqqry2e5yuVBTU+NTc619XPkZ16vxbr8WnU4Hg8Hg8/C3y3ciZ8ghIiLqSR0KObfffjvKysp8Xjt+/DgGDBgAABg0aBBMJhMKCwul7Xa7Hbt374bZbAYAmM1m1NXVobi4WKrZunUrPB4PMjMzpZodO3agtfVyMCgoKMDQoUOlK7nMZrPP53hrvJ8TKBhyiIiI5NGhkLNgwQLs2rULL774Ir7++mu8//77WLVqFXJycgAACoUC8+fPxx/+8Ad88sknKC0txcMPP4zExERMmjQJQNvIzz333IPHHnsMe/bswZdffom5c+fiwQcfRGJiIgDg5z//ObRaLWbNmoXDhw9j7dq1WL58OXJzc6Ve5s2bh82bN+OVV17BsWPH8Nxzz2Hfvn2YO3duNx2a7uGdk8P7VxEREfWwjl62tX79ejF8+HCh0+lEamqqWLVqlc92j8cjnn32WZGQkCB0Op24++67RVlZmU/NxYsXxbRp00RkZKQwGAxi5syZor6+3qfmq6++EuPHjxc6nU70799fvPTSS1f1sm7dOnHTTTcJrVYrhg0bJjZu3Nih7+LvS8iFEOL36w+LAU9uEC9uPOK3zyAiIupN2vv7rRBCCLmDllzsdjuMRiNsNpvf5uf8qfAEXik4jmnjkpE3eYRfPoOIiKg3ae/vN+9d5WfeWzvYOCeHiIioRzHk+Jk0J4fr5BAREfUohhw/M3DFYyIiIlkw5PiZdCdynq4iIiLqUQw5fnZ5JIenq4iIiHoSQ46fGa+YeNyLL2QjIiLqcQw5fuadeOz2CDQ53TJ3Q0RE1Hsw5PhZmEYFtVIBgJOPiYiIehJDjp8pFIorJh9zXg4REVFPYcjpAQa99/5VHMkhIiLqKQw5PUCafNzEkENERNRTGHJ6gHS6iiM5REREPYYhpwdIa+VwQUAiIqIew5DTA6T7V3FBQCIioh7DkNMDOJJDRETU8xhyeoDhilWPiYiIqGcw5PQATjwmIiLqeQw5PSA2QgsAOFHVwPtXERER9RCGnB4wfkgcwjQqnLzQiH3f1srdDhERUa/AkNMDDHoNfjKyHwDgg93lMndDRETUOzDk9JBp41IAABtKz6OuySlzN0RERKGPIaeHjEqOxs39DHC6PPhw/1m52yEiIgp5DDk9RKFQ4OfjkgEAH+wp5wRkIiIiP2PI6UE/G90fYRoVTlQ1oJgTkImIiPyKIacHXTkB+X1OQCYiIvIrhpwexgnIREREPYMhp4dxAjIREVHPYMjpYd+dgFzb6ITHw0nIRERE3U0hevFlPna7HUajETabDQaDoec+t6UVmS8UornVDQBQKxWIi9Shb5QOv7xtIKZkJPVYL0RERMGmvb/fHMmRgUGvwfysIYgOb7txp8sjYLW3oPSsDa9vPSFzd0RERKFBLXcDvdV/3HUj/uOuG+F0eXCx0YGS8jrMeW8/bM28UzkREVF3YMiRmVatRD9jGBQpCgBAfYsLQggoFAqZOyMiIgpuPF0VIAxhbXnT7RFocrpl7oaIiCj4MeQEiDCNCmpl2+iNvYWnrIiIiLqKISdAKBQKROnbRnPszS6ZuyEiIgp+DDkBxBDWdrVVPUdyiIiIuowhJ4AY9G0hh6eriIiIuo4hJ4B4Jx/zdBUREVHXMeQEkCgdT1cRERF1lw6FnOeeew4KhcLnkZqaKm1vaWlBTk4OYmNjERkZiSlTpqCystJnH+Xl5cjOzkZ4eDji4+OxcOFCuFy+Ixfbtm3DmDFjoNPpMHjwYKxevfqqXlasWIGBAwdCr9cjMzMTe/bs6chXCUjSSE4LR3KIiIi6qsMjOcOGDcP58+elxxdffCFtW7BgAdavX4/8/Hxs374d586dw+TJk6Xtbrcb2dnZcDqd2LlzJ959912sXr0aS5YskWpOnTqF7OxsTJgwASUlJZg/fz4effRRbNmyRapZu3YtcnNzsXTpUuzfvx8jR46ExWJBVVVVZ49DQJDm5HDVYyIioq4THbB06VIxcuTIa26rq6sTGo1G5OfnS68dPXpUABBFRUVCCCE2bdoklEqlsFqtUs3KlSuFwWAQDodDCCHEokWLxLBhw3z2PXXqVGGxWKTn48aNEzk5OdJzt9stEhMTRV5eXke+jrDZbAKAsNlsHXqfv7xWcFwMeHKDeOp/v5K7FSIiooDV3t/vDo/knDhxAomJibjhhhswffp0lJeXAwCKi4vR2tqKrKwsqTY1NRUpKSkoKioCABQVFSE9PR0JCQlSjcVigd1ux+HDh6WaK/fhrfHuw+l0ori42KdGqVQiKytLqrkeh8MBu93u8wgkPF1FRETUfToUcjIzM7F69Wps3rwZK1euxKlTp3DHHXegvr4eVqsVWq0W0dHRPu9JSEiA1WoFAFitVp+A493u3fZ9NXa7Hc3Nzaiurobb7b5mjXcf15OXlwej0Sg9kpOTO/L1/Y6nq4iIiLpPh27Qee+990p/HjFiBDIzMzFgwACsW7cOYWFh3d5cd1u8eDFyc3Ol53a7PaCCjrTiMUdyiIiIuqxLl5BHR0fjpptuwtdffw2TyQSn04m6ujqfmsrKSphMJgCAyWS66mor7/MfqjEYDAgLC0NcXBxUKtU1a7z7uB6dTgeDweDzCCRc8ZiIiKj7dCnkNDQ04JtvvkG/fv2QkZEBjUaDwsJCaXtZWRnKy8thNpsBAGazGaWlpT5XQRUUFMBgMCAtLU2quXIf3hrvPrRaLTIyMnxqPB4PCgsLpZpgdfl0FUdyiIiIuqpDIee3v/0ttm/fjtOnT2Pnzp24//77oVKpMG3aNBiNRsyaNQu5ubn4/PPPUVxcjJkzZ8JsNuPWW28FAEycOBFpaWl46KGH8NVXX2HLli145plnkJOTA51OBwCYPXs2Tp48iUWLFuHYsWN44403sG7dOixYsEDqIzc3F2+99RbeffddHD16FHPmzEFjYyNmzpzZjYem512eeMyRHCIioq7q0JycM2fOYNq0abh48SL69u2L8ePHY9euXejbty8A4NVXX4VSqcSUKVPgcDhgsVjwxhtvSO9XqVTYsGED5syZA7PZjIiICMyYMQPPP/+8VDNo0CBs3LgRCxYswPLly5GUlIS3334bFotFqpk6dSouXLiAJUuWwGq1YtSoUdi8efNVk5GDTdSlkRyny4OWVjf0GpXMHREREQUvhRBCyN2EXOx2O4xGI2w2W0DMz/F4BG58ehOEAPY+nYW+UTq5WyIiIgo47f395r2rAohSqUCkjqesiIiIugNDToDhWjlERETdgyEnwHjXyqnnWjlERERdwpATYLxr5fB0FRERUdcw5AQYrpVDRETUPRhyAoxBOl3FkRwiIqKuYMgJMDxdRURE1D0YcgKMdySHp6uIiIi6hiEnwHhXPeZIDhERUdcw5AQY7/2reAk5ERFR1zDkBBguBkhERNQ9GHICDCceExERdQ+GnADDFY+JiIi6B0NOgOHpKiIiou7BkBNgvKerGp1uuNwembshIiIKXgw5AcZ7ugrgKSsiIqKuYMgJMBqVEmEaFQCGHCIioq5gyAlA3rVyeIUVERFR5zHkBCBOPiYiIuo6hpwA5J2XY+fpKiIiok5jyAlAXBCQiIio6xhyAhBPVxEREXUdQ04A4qrHREREXceQE4B4uoqIiKjrGHIC0OXTVRzJISIi6iyGnADEdXKIiIi6jiEnAEVdGsmpZ8ghIiLqNIacAGTwrpPD01VERESdxpATgDjxmIiIqOsYcgKQgZeQExERdRlDTgAyXDEnx+MRMndDREQUnBhyApD3dJVHAI1OjuYQERF1BkNOANKpldCq2v6n4U06iYiIOochJwApFIorbu3AycdERESdwZAToKQrrHgZORERUacw5ASoy2vlcCSHiIioMxhyApS06rGDIYeIiKgzGHIClHT/Kp6uIiIi6hSGnAB1+U7kHMkhIiLqDIacAMVbOxAREXVNl0LOSy+9BIVCgfnz50uvtbS0ICcnB7GxsYiMjMSUKVNQWVnp877y8nJkZ2cjPDwc8fHxWLhwIVwu39My27Ztw5gxY6DT6TB48GCsXr36qs9fsWIFBg4cCL1ej8zMTOzZs6crXyegROl4awciIqKu6HTI2bt3L/7yl79gxIgRPq8vWLAA69evR35+PrZv345z585h8uTJ0na3243s7Gw4nU7s3LkT7777LlavXo0lS5ZINadOnUJ2djYmTJiAkpISzJ8/H48++ii2bNki1axduxa5ublYunQp9u/fj5EjR8JisaCqqqqzXymgcCSHiIioi0Qn1NfXiyFDhoiCggJx1113iXnz5gkhhKirqxMajUbk5+dLtUePHhUARFFRkRBCiE2bNgmlUimsVqtUs3LlSmEwGITD4RBCCLFo0SIxbNgwn8+cOnWqsFgs0vNx48aJnJwc6bnb7RaJiYkiLy+v3d/DZrMJAMJms7X/y/eQD/dXiAFPbhDT39oldytEREQBpb2/350aycnJyUF2djaysrJ8Xi8uLkZra6vP66mpqUhJSUFRUREAoKioCOnp6UhISJBqLBYL7HY7Dh8+LNV8d98Wi0Xah9PpRHFxsU+NUqlEVlaWVHMtDocDdrvd5xGoonSXb9JJREREHafu6BvWrFmD/fv3Y+/evVdts1qt0Gq1iI6O9nk9ISEBVqtVqrky4Hi3e7d9X43dbkdzczNqa2vhdruvWXPs2LHr9p6Xl4ff/e537fuiMrt8uopzcoiIiDqjQyM5FRUVmDdvHt577z3o9Xp/9eQ3ixcvhs1mkx4VFRVyt3Rdl9fJ4UgOERFRZ3Qo5BQXF6OqqgpjxoyBWq2GWq3G9u3b8frrr0OtViMhIQFOpxN1dXU+76usrITJZAIAmEymq6628j7/oRqDwYCwsDDExcVBpVJds8a7j2vR6XQwGAw+j0DlXSenvsUFIYTM3RAREQWfDoWcu+++G6WlpSgpKZEeY8eOxfTp06U/azQaFBYWSu8pKytDeXk5zGYzAMBsNqO0tNTnKqiCggIYDAakpaVJNVfuw1vj3YdWq0VGRoZPjcfjQWFhoVQT7Lx3IXe6PXC4PDJ3Q0REFHw6NCcnKioKw4cP93ktIiICsbGx0uuzZs1Cbm4uYmJiYDAY8MQTT8BsNuPWW28FAEycOBFpaWl46KGHsGzZMlitVjzzzDPIycmBTqcDAMyePRt//vOfsWjRIjzyyCPYunUr1q1bh40bN0qfm5ubixkzZmDs2LEYN24cXnvtNTQ2NmLmzJldOiCBIkKrhlIBeETbKSu9RiV3S0REREGlwxOPf8irr74KpVKJKVOmwOFwwGKx4I033pC2q1QqbNiwAXPmzIHZbEZERARmzJiB559/XqoZNGgQNm7ciAULFmD58uVISkrC22+/DYvFItVMnToVFy5cwJIlS2C1WjFq1Chs3rz5qsnIwUqpVCBKr4GtuRX2llbEG4JvDhQREZGcFKIXT/iw2+0wGo2w2WwBOT9n/P+3FWdqm/Hhr27DmJQ+crdDREQUENr7+817VwUw3qSTiIio8xhyAph0GTnXyiEiIuowhpwAFhOhBQCcvNAgcydERETBhyEngN2d2jaJ+u/FZ+Dx9NqpU0RERJ3CkBPA7kvvhyi9Gmdqm7Hzm4tyt0NERBRUGHICWJhWhUmj+gMAPthbLnM3REREwYUhJ8BNvSUZAPCPw1bUNDpl7oaIiCh4MOQEuOH9jUjvb0SrW+DD/WfkboeIiChoMOQEAe9oztq9FbxZJxERUTsx5ASBn45KhF6jxImqBuwvr5W7HSIioqDAkBMEDHoNstMTAQBr9lTI3A0REVFwYMgJEtPGtZ2y2nDwPOpbeJsHIiKiH8KQEyQyBvTBjX0j0NzqxidfnZO7HSIiooDHkBMkFAoFHrwlBUDbBGQiIiL6fgw5QWTymP5QKRU4eMaG09WNcrdDREQU0BhygkhspA7mG2IBAJ8essrcDRERUWBjyAky96abAACfHjovcydERESBjSEnyExMM0GpAA6esaGipknudoiIiAIWQ06Q6Rulw7hBMQCAzTxlRUREdF0MOUHovvR+AIBNPGVFRER0XQw5QcgyzASFAjhQXodzdc1yt0NERBSQGHKCUIJBj7ED+gDgKSsiIqLrYcgJUvcObztlxZBDRER0bQw5Qeqe4W2Xku/9tgZV9haZuyEiIgo8DDlBKjE6DKOSoyEEsOUwR3OIiIi+iyEniN13aWHATaUMOURERN/FkBPEvPNydp+6iOoGh8zdEBERBRaGnCCWHBOO9P5GeASw/qtzcrdDREQUUBhygty/ZSQBAF4vPIGaRqfM3RAREQUOhpwg9/PMFKSaolDb1IoXNx2Vux0iIqKAwZAT5DQqJV64Px0KBfD34jPYdfKi3C0REREFBIacEJAxoA+mjUsBADz9USkcLrfMHREREcmPISdEPGlJRVykFt9caMSq7SflboeIiEh2DDkhwhiuwbM/TgMA/Onzr3G6ulHmjoiIiOTFkBNCfjoyEXcMiYPT5cGz/3dI7naIiIhkxZATQhQKBX7/s+FQKxX454lqnKltkrslIiIi2TDkhJiBcRFI7RcFADh4xiZzN0RERPJhyAlBI5OiAQBfVdTJ2gcREZGcGHJCkBRyztTJ2gcREZGcOhRyVq5ciREjRsBgMMBgMMBsNuPTTz+Vtre0tCAnJwexsbGIjIzElClTUFlZ6bOP8vJyZGdnIzw8HPHx8Vi4cCFcLpdPzbZt2zBmzBjodDoMHjwYq1evvqqXFStWYODAgdDr9cjMzMSePXs68lVC2sjkaABA6Rkb3B4hbzNEREQy6VDISUpKwksvvYTi4mLs27cPP/rRj/Czn/0Mhw8fBgAsWLAA69evR35+PrZv345z585h8uTJ0vvdbjeys7PhdDqxc+dOvPvuu1i9ejWWLFki1Zw6dQrZ2dmYMGECSkpKMH/+fDz66KPYsmWLVLN27Vrk5uZi6dKl2L9/P0aOHAmLxYKqqqquHo+QMDg+EuFaFRqdbnxzoUHudoiIiOQhuqhPnz7i7bffFnV1dUKj0Yj8/Hxp29GjRwUAUVRUJIQQYtOmTUKpVAqr1SrVrFy5UhgMBuFwOIQQQixatEgMGzbM5zOmTp0qLBaL9HzcuHEiJydHeu52u0ViYqLIy8vrUO82m00AEDabrUPvCwYPvLlTDHhyg1i3t1zuVoiIiLpVe3+/Oz0nx+12Y82aNWhsbITZbEZxcTFaW1uRlZUl1aSmpiIlJQVFRUUAgKKiIqSnpyMhIUGqsVgssNvt0mhQUVGRzz68Nd59OJ1OFBcX+9QolUpkZWVJNdfjcDhgt9t9HqFq1KVTVpyXQ0REvVWHQ05paSkiIyOh0+kwe/ZsfPTRR0hLS4PVaoVWq0V0dLRPfUJCAqxWKwDAarX6BBzvdu+276ux2+1obm5GdXU13G73NWu8+7ievLw8GI1G6ZGcnNzRrx80RiQZAQBfVfAyciIi6p06HHKGDh2KkpIS7N69G3PmzMGMGTNw5MgRf/TW7RYvXgybzSY9Kioq5G7Jb7xXWB2z2tHSyht2EhFR76Pu6Bu0Wi0GDx4MAMjIyMDevXuxfPlyTJ06FU6nE3V1dT6jOZWVlTCZTAAAk8l01VVQ3quvrqz57hVZlZWVMBgMCAsLg0qlgkqlumaNdx/Xo9PpoNPpOvqVg1JSnzDERGhR0+jE0fN2jE7pI3dLREREParL6+R4PB44HA5kZGRAo9GgsLBQ2lZWVoby8nKYzWYAgNlsRmlpqc9VUAUFBTAYDEhLS5NqrtyHt8a7D61Wi4yMDJ8aj8eDwsJCqYbabvEw8tIpK658TEREvVGHRnIWL16Me++9FykpKaivr8f777+Pbdu2YcuWLTAajZg1axZyc3MRExMDg8GAJ554AmazGbfeeisAYOLEiUhLS8NDDz2EZcuWwWq14plnnkFOTo40wjJ79mz8+c9/xqJFi/DII49g69atWLduHTZu3Cj1kZubixkzZmDs2LEYN24cXnvtNTQ2NmLmzJndeGiC38jkaHxedoErHxMRUa/UoZBTVVWFhx9+GOfPn4fRaMSIESOwZcsW/Ou//isA4NVXX4VSqcSUKVPgcDhgsVjwxhtvSO9XqVTYsGED5syZA7PZjIiICMyYMQPPP/+8VDNo0CBs3LgRCxYswPLly5GUlIS3334bFotFqpk6dSouXLiAJUuWwGq1YtSoUdi8efNVk5F7O++8nBJeYUVERL2QQgjRa5fEtdvtMBqNsNlsMBgMcrfT7S42OJDxh88AAAefmwiDXiNzR0RERF3X3t9v3rsqhMVG6pDUJwxA2y0eiIiIehOGnBA3kosCEhFRL8WQE+JGSosC1snbCBERUQ9jyAlx3snHXPmYiIh6G4acEDe8vxFKBWC1t6DS3iJ3O0RERD2GISfERejUGBIfBYCnrIiIqHdhyOkFRia3zctZteMkvjhRDY+n164aQEREvQhDTi/wo9S2RRL3fVuLX/z3bvzLf23Dis+/RlU9T18REVHo4mKAIbwY4JUOn7NhzZ4KfHzgLOodLgBApE6NbQv/BXGRveOmpUREFBq4GCD5GJZoxO8nDceep7PwXw+MRN8oHRocLuw7XSt3a0RERH7BkNPLhGlV+LeMJNydGg8AKD1bJ29DREREfsKQ00sN7982Gbn0rF3mToiIiPyDIaeXGnFpJeTSM3XoxdOyiIgohDHk9FJDTVHQqBSobWrF2bpmudshIiLqdgw5vZROrcJQU9sigbxDORERhSKGnF4sXZqXw5BDREShhyGnF0vvHw2AIYeIiEITQ04vduVIDicfExFRqGHI6cVuMkVCq1KirqkVZ2o5+ZiIiEILQ04vduXk44OcfExERCGGIaeXS0/i5GMiIgpNDDm93OV5OXXyNkJERNTNGHJ6OSnknOHkYyIiCi0MOb3cTQlR0KqUsLe4UF7TJHc7RERE3YYhp5fTqpW4ud+llY85L4eIiEIIQw5dviM5r7AiIqIQwpBDl+9IzpEcIiIKIQw5dHkkhysfExFRCGHIobbJx2ol6ltc+PYiJx8TEVFoYMghaFRK3NzPAAA4yFNWREQUIhhyCAAw4tIpq0MMOUREFCIYcgjA5cnHnx2phMvtkbkbIiKirmPIIQDAPcNN6BOuwcnqRny4/6zc7RAREXUZQw4BAKL0GuRMGAwAePWz42hpdcvcERERUdcw5JDkF7cOQD+jHudtLfjbrm/lboeIiKhLGHJIoteoMD9rCABgxedfo76lVeaOiIiIOo8hh3xMGZOEG/pGoLapFW/985Tc7RAREXUaQw75UKuUWDhxKADg7X+eRHWDQ+aOiIiIOochh65yz3ATRiQZ0eR0Y8XnX8vdDhERUad0KOTk5eXhlltuQVRUFOLj4zFp0iSUlZX51LS0tCAnJwexsbGIjIzElClTUFlZ6VNTXl6O7OxshIeHIz4+HgsXLoTL5fKp2bZtG8aMGQOdTofBgwdj9erVV/WzYsUKDBw4EHq9HpmZmdizZ09Hvg5dh0KhwCJLKgDgvV3lqKjhrR6IiCj4dCjkbN++HTk5Odi1axcKCgrQ2tqKiRMnorGxUapZsGAB1q9fj/z8fGzfvh3nzp3D5MmTpe1utxvZ2dlwOp3YuXMn3n33XaxevRpLliyRak6dOoXs7GxMmDABJSUlmD9/Ph599FFs2bJFqlm7di1yc3OxdOlS7N+/HyNHjoTFYkFVVVVXjgddMn5IHG67MRZOtwevF56Qux0iIqKOE11QVVUlAIjt27cLIYSoq6sTGo1G5OfnSzVHjx4VAERRUZEQQohNmzYJpVIprFarVLNy5UphMBiEw+EQQgixaNEiMWzYMJ/Pmjp1qrBYLNLzcePGiZycHOm52+0WiYmJIi8vr93922w2AUDYbLYOfOveY/+3NWLAkxvEoKc2iBOVdrnbISIiEkK0//e7S3NybLa2+xzFxMQAAIqLi9Ha2oqsrCypJjU1FSkpKSgqKgIAFBUVIT09HQkJCVKNxWKB3W7H4cOHpZor9+Gt8e7D6XSiuLjYp0apVCIrK0uquRaHwwG73e7zoOsbndIH/5qWAI8A/lhwXO52iIiIOqTTIcfj8WD+/Pm4/fbbMXz4cACA1WqFVqtFdHS0T21CQgKsVqtUc2XA8W73bvu+GrvdjubmZlRXV8Ptdl+zxruPa8nLy4PRaJQeycnJHf/ivcxvJt4EhQLYVGpF6RnevJOIiIJHp0NOTk4ODh06hDVr1nRnP361ePFi2Gw26VFRUSF3SwEv1WTAz0YmAgD+6x9lP1BNREQUODoVcubOnYsNGzbg888/R1JSkvS6yWSC0+lEXV2dT31lZSVMJpNU892rrbzPf6jGYDAgLCwMcXFxUKlU16zx7uNadDodDAaDz4N+2IJ/vQlqpQLbj1/A7pMX5W6HiIioXToUcoQQmDt3Lj766CNs3boVgwYN8tmekZEBjUaDwsJC6bWysjKUl5fDbDYDAMxmM0pLS32ugiooKIDBYEBaWppUc+U+vDXefWi1WmRkZPjUeDweFBYWSjXUfQbERmDqLW2n9v7rH2UQQsjcERERUTt0ZDbznDlzhNFoFNu2bRPnz5+XHk1NTVLN7NmzRUpKiti6davYt2+fMJvNwmw2S9tdLpcYPny4mDhxoigpKRGbN28Wffv2FYsXL5ZqTp48KcLDw8XChQvF0aNHxYoVK4RKpRKbN2+WatasWSN0Op1YvXq1OHLkiHj88cdFdHS0z1VbP4RXV7Xf+bpmcdPTm8SAJzeIrccq5W6HiIh6sfb+fnco5AC45uOdd96Rapqbm8WvfvUr0adPHxEeHi7uv/9+cf78eZ/9nD59Wtx7770iLCxMxMXFid/85jeitbXVp+bzzz8Xo0aNElqtVtxwww0+n+H1pz/9SaSkpAitVivGjRsndu3a1ZGvw5DTQS9sPCIGPLlBjP1DgfjixAW52yEiol6qvb/fCiF677kHu90Oo9EIm83G+TntUNfkxANvFuFEVQMUCuDxO27AbyYOhVbNu4MQEVHPae/vN3+dqN2iw7X4ZO54/DwzBUIAf9lxEpNXfolvLjTI3RoREdFVGHKoQ8K0Krx4fzr+8lAGosM1OHTWjh+//gX2l9fK3RoREZEPhhzqFMswEzbPuxPjBsWgudWNJ/9+EE6XR+62iIiIJAw51Gkmox6rHspAbIQWJ6oasGrHN3K3REREJGHIoS6JDtfi2R+3rW/0+tavcaq68QfeQURE1DMYcqjLfjYqEXcMiYPT5cEzH5dysUAiIgoIDDnUZQqFAn+YNBw6tRJffn0RHx04K3dLREREDDnUPQbERmBe1hAAwB82HkVNo1PmjoiIqLdjyKFu89gdNyDVFIWaRiee+GA/PjtSiSanS+62iIiol+KKx1zxuFvtL6/Fv63cCc+lf6u0aiVuvSEWdw6JQ2ykFnq1CnqtCnq1Cv2MegyIDYdCoZC3aSIiCirt/f1myGHI6XYHymvx0YGz2HqsCmdqm7+3NiZCizEpfZAxoA9uGdj2T4YeIiL6Pgw57cCQ419CCHxzoQFbj1Vh3+laNDndaGl1o/nS40xt81ULCM6+60Y8dW+qTB0TEVEwYMhpB4YceTlcbhw+Z8f+b2ux51QN/nGkEiqlApvn3YEhCVFyt0dERAGKN+ikgKdTqzAmpQ8eveMGrHp4LCamJcDtEXh+wxGutUNERF3GkEMB4+nsm6FVKfHPE9XYeqxK7naIiCjIMeRQwBgQG4FHxg8C0LbWDm/4SUREXcGQQwFl7o8GIy5Sh1PVjfifotNyt0NEREGMIYcCSqROjUWWoQCA5Z+dQHWDQ+aOiIgoWDHkUMD5t4wkpPc3ot7hwiv/OC53O0REFKQYcijgKJUKLPlJGgBgzd5yHCivlbkjIiIKRgw5FJBuGRiDyaP7Qwjgt/lfoaXVLXdLREQUZBhyKGAt+Uka+kbp8M2FRrxawNNWRETUMQw5FLCiw7XIuz8dAPDWP0+i+FuetiIiovZjyKGAlpWWgMlj+sMjgIU8bUVERB3AkEMBb+mPhyHBoMPJ6ka88o8yudshIqIgwZBDAc8YrsFLk0cAAN7+4hT+eeKCzB0REVEwYMihoDAhNR4PZCRBCOCh/96D2f+vGGXWernbIiKiAMaQQ0Fj6U+H4f7R/aFQAJsPW3HP8h144oMD+OZCg9ytERFRAFIIIYTcTcjFbrfDaDTCZrPBYDDI3Q610/HKerz22XFsKrUCAJSKtlWS52XdhP7RYTJ3R0RE/tbe32+GHIacoHX4nA2vFpzAZ0crAQBatRIP3ToAv/qXGxEbqZO5OyIi8heGnHZgyAkN+8trsWzzMew6WQMAiNCqYBlmwk2mKAxNiMJNpigkGvVQKBQyd0pERN2BIacdGHJChxAC/zxRjZe3lKH0rO2q7XGROrz8wAhMGBovQ3dERNSdGHLagSEn9HjDzsEzdSirbMBxaz2+udAAl0dArVTgtQdH4ccjEuVuk4iIuqC9v9/qHuyJyO8UCgXuvKkv7rypr/RaS6sbC/9+EOu/OocnPjiA+hYXpo1LkbFLIiLqCbyEnEKeXqPCa1NH4eeZKRACWPxhKf6y/Ru52yIiIj/jSA71CiqlAi9MGg6DXoM3t3+DvE+P4YuvqxEXqYNeo0KYRoVwrQph2rZ/RmjVCNOq0CdcC5NRB5MxDJE6/t+FiCiY8G9t6jUUCgWeujcVhjA1lm0uwz9PVHfo/VE6NZJiwvHUvam464rTYUREFJg48ZgTj3ulfadrcPS8Hc2tbjQ7PWhudaOl1Y0mpwuNTjeanW40OlyobXLivK0F9S0u6b3hWhX+d85tuLkf/50hIpIDr65qB4Ycaq8GhwtWWwuWfnIIX359EUl9wvDJ3PGIidDK3RoRUa/T3t9vTjwmaodInRqD4yPx52ljkBITjjO1zch5bz9a3R65WyMiouvocMjZsWMHfvKTnyAxMREKhQIff/yxz3YhBJYsWYJ+/fohLCwMWVlZOHHihE9NTU0Npk+fDoPBgOjoaMyaNQsNDb43WTx48CDuuOMO6PV6JCcnY9myZVf1kp+fj9TUVOj1eqSnp2PTpk0d/TpEHdInQou3Hh6LcK0KRScv4oWNR+VuiYiIrqPDIaexsREjR47EihUrrrl92bJleP311/Hmm29i9+7diIiIgMViQUtLi1Qzffp0HD58GAUFBdiwYQN27NiBxx9/XNput9sxceJEDBgwAMXFxXj55Zfx3HPPYdWqVVLNzp07MW3aNMyaNQsHDhzApEmTMGnSJBw6dKijX4moQ4aaovDHfx8FAFi98zT+365v4XRxRIeIKNB0aU6OQqHARx99hEmTJgFoG8VJTEzEb37zG/z2t78FANhsNiQkJGD16tV48MEHcfToUaSlpWHv3r0YO3YsAGDz5s247777cObMGSQmJmLlypV4+umnYbVaodW2zXl46qmn8PHHH+PYsWMAgKlTp6KxsREbNmyQ+rn11lsxatQovPnmm+3qn3NyqCte++w4XvusbZRSpVQgJSYcN/aNwI19IzFxWAIyBsTI3CERUWiSZU7OqVOnYLVakZWVJb1mNBqRmZmJoqIiAEBRURGio6OlgAMAWVlZUCqV2L17t1Rz5513SgEHACwWC8rKylBbWyvVXPk53hrv51yLw+GA3W73eRB11q9/NAS/vG0gInVquD0Cp6ob8dnRKvxlx0lMWVmEyW98ic2HzsPt6bVz+4mIZNWt6+RYrVYAQEJCgs/rCQkJ0jar1Yr4eN+bJKrVasTExPjUDBo06Kp9eLf16dMHVqv1ez/nWvLy8vC73/2uE9+M6GpKpQLP/XQYlv4kDVX1DnxT1YBvLjTgQHkdNhw8j/3ldZj9t/0YEBuOx++8AdNuSYFSyTuhExH1lF51ddXixYths9mkR0VFhdwtUQhQKBRIMOhx2+A4PGQeiD9OHYUvnpqAuRMGwximwbcXm/D0R4fw9Mel8HBUh4iox3RryDGZTACAyspKn9crKyulbSaTCVVVVT7bXS4XampqfGqutY8rP+N6Nd7t16LT6WAwGHweRP4QH6XHby1DUbT4R3jq3lQoFcAHeyqw6H8P8vQVEVEP6daQM2jQIJhMJhQWFkqv2e127N69G2azGQBgNptRV1eH4uJiqWbr1q3weDzIzMyUanbs2IHW1lappqCgAEOHDkWfPn2kmis/x1vj/RyiQBCuVWP2XTfi1amjoFIq8PfiM/jNuhK4uL4OEZHfdTjkNDQ0oKSkBCUlJQDaJhuXlJSgvLwcCoUC8+fPxx/+8Ad88sknKC0txcMPP4zExETpCqybb74Z99xzDx577DHs2bMHX375JebOnYsHH3wQiYmJAICf//zn0Gq1mDVrFg4fPoy1a9di+fLlyM3NlfqYN28eNm/ejFdeeQXHjh3Dc889h3379mHu3LldPypE3exno/rj9QdHQ61U4OOSc5i/toQLCRIR+VmHLyHftm0bJkyYcNXrM2bMwOrVqyGEwNKlS7Fq1SrU1dVh/PjxeOONN3DTTTdJtTU1NZg7dy7Wr18PpVKJKVOm4PXXX0dkZKRUc/DgQeTk5GDv3r2Ii4vDE088gSeffNLnM/Pz8/HMM8/g9OnTGDJkCJYtW4b77ruv3d+Fl5BTT9ty2Iq57+9Hq1sgNkKLpJhwJEWHITFajxv7RmLS6P7Qa1Ryt0lEFNB476p2YMghOWw9Vom57x9Ak9N91bYBseF4YVI6xg+Jk6EzIqLgwJDTDgw5JJcGhwunqxtxtq4ZZ2ubcbauGRsPnofV3rYy+P2j++OZ7JsRG6mTuVMiosDDkNMODDkUSBocLvzXljK8W3QaQgDR4RpMGtV2+kqrVkKrUiBcq0Z6khHp/Y08rUVEvRZDTjsw5FAg+qqiDk99WIqj56+/IrdWpcSIJCPGDozBvwzti8xBMVAouNAgEfUODDntwJBDgcrl9uDD/Wdx6mIjnC4PnC4PWt0e1DQ6sb+8DtUNDp/64f0N+I87b8S9w01Qq3rVGp9E1Asx5LQDQw4FIyEEvr3YhL2na7DrZA02lp5DS2vb5ejJMWF4dPwNmDA0HskxYRzdIaKQxJDTDgw5FApqGp34n6LT+J+ib1HT6JRej9KpcXM/A27uF4XB8ZHoG6VH3ygt+kbqERelRbi2W29dR0TUYxhy2oEhh0JJs9ONvxdXIL/4DI6dr4fzBxYbjNCqEBelQ99IHeIidRgYF4GptyRjUFxED3VMRNQ5DDntwJBDoarV7cE3Fxpw9LwdR87ZcfpiE6obHKhucOBCvUM6vfVdCgVwd2oCHr1jECczE1HAYshpB4Yc6o2EEGhwuFDd4JRCz4V6B7Yfv4Ctxy7fPHd4fwP+bUwSxg+Jw419Ixl4iChgMOS0A0MOka+vqxrwzpen8L/7z/iM9iQYdLh9cBzGDYxBXKQOxnANDHoNjGEa6DVKKBQKqJQKKBWAUqGA8ornDEdE1N0YctqBIYfo2moanfh7cQV2HK/GntM1cLo6fzNRpQLQqJTQqpXQqZXQqpTQa1UYmhCFUcnRGJUcjfQkIydCE1G7MeS0A0MO0Q9raXWj+NtafPl1NQ6ds8PW5IStuRX2Fhdsza1we7r+V4hKqcCAmHDERmoRE9H26BOuhU6tgkoJKJUKqJUKxEXqcM9wEwMRUS/HkNMODDlEXSOEgEcAbo+ARwgIAbiFgNvj+2h1e+B0e6SFDetbXDh0zoYD5bUoqahDpd3xwx92iTFMg2njUvCweQASo8P8+O2IKFAx5LQDQw5RYDhva8bp6ibUNDpR0+RETYMTtU1OON0eeDwCrkthaX95Lb692ASgbfTnvvR+yE43Ia2fkYsfEvUiDDntwJBDFFzcHoHCo5X465ensOtkjc827+KHQxIiYQzTIEKnRpRejUidGnqNChqVEhqVAlq1EhqV8tIE6csTpaP0apiMet74lCgIMOS0A0MOUfA6fM6G93eX46szdThubfjBxQ/bKzpcA5NBj35GPYYkROHmflG4uZ8BN/aNhIb3BSMKCAw57cCQQxQavIsfHjlnx6nqRjQ4XGhocbX90+GCo7VtTlCr9GibQ+QRAh4P4BECtuZWNDnd1/0MrUqJlNhwxEVqERvpXSlai1tviMWYlD5QKnmqjKintPf3m5coEFHQ06iUSDUZkGrq/H+sCCFQ73DBamvBeVsLztQ2ocxaj6Pn7Th2vh71Dhe+rmrA11VXv7d/dBh+PLIffjIiEcMSDZwbRBQgOJLDkRwi+gFCCJypbUZ5jff2GE5cbHCgvKYJ28ouoMHhkmr7RukQrlVBrVRAo1JCrVJApVBAcWkOkErZtlBimEaFcJ0a4RoVInRq6DRK6NQq6C6tJxShU+PGvpEYaoqCMUwj47cnCjwcySEi6iYKhQLJMeFIjgm/altLqxufH6vC+oPnUHi0Chfq2385fHslGvVI7WdAYrQeOrUK+kuBSK9RXppQ3bbYolalhCFMjZSYcCT1Ceckaur1OJLDkRwi6iYNDhdOXmiQ5v243AKtHk/bekKetjWEhBBodQs0O91ocrrQ6HSj2elGS6sbjkvrCDlcbtQ1t+JEZQPO1jV3qheFAjAZ9EiOCcfA2HAMiI3AwNgIDIgNR2J0GMI0baNGnEtEwYgjOUREPSxSp8aIpOhu3aetuRXHK+txzFqP6noHHC6PFIgcre4rJlQLOF0e1DQ6UV7ThAaHC+cvzS/ac6rmuvvXqZUI06oQG6FFYnQY+hn16GcMQ1yUDmrv/ceggOI79yFTAFCrFOgTrkVspBZxkTrERGh5BRoFFI7kcCSHiEKMEEIKO99e9D4acfpiI7692ISLjU6/fbZOrWybd6RQQHlpXlJ8lA6J0fpLISoMMREaaX0ipbJtraK2uUiqq+YmaS+9rlUrEa5te50Tu4kjOUREvZRCoUBspA6xkTqMTulz1Xa3R6Cl1Y3m1rbTZM1ONy7UO3DO1oJzdc04b2vGxQYnPKItMAm0XWYPAEIA3v8ydrnbRo4uNjpR0+iE2yPguMbNXKsbHDhy3t4t302lVCBC2zZZOyZCi7ED+uDWG2KReUMsYiK03fIZFDo4ksORHCKiLvN4BOqaW9HkdEnzj9yetlNolfYWnLM141xdM87WNsPe4rq0TlFbiPLWOS7NR/KeknNKc5Q8cLXjRrCppij0/879zLyn2b67unW8QQ+TQY8Egw4JBj2MYRoYwzWI1Ko5TykIcCSHiIh6jFKpkO4g/11piV3/j0i3R7RN1Ha40eh0odHhwpnaZuw+eRG7Ttag7NK8pWPW+i59jlIBROk1iInQom+UDvFROsRH6dE3SgetWgmVou27KhUKhGtVSOoTjuSYMCRE6RmOAhBHcjiSQ0QU9C42OLD3dC3sza0+r3sunW5ze4Q0amRrdqGyvgWVtpa2f9odsDW3wnmNU23tpVUp0b9PGAxhGuhUyktzi9rmFKmVbeslqZUKqFVtl/qrlQpo1EpolAroNCpEh2sQE65Fn0tBMVyrglLRtqaSUtH2Xq20P0Wvn5fEkRwiIuo1YiN1uGe4qUv7aGl1w97cCltzKy42OlFV70CVvQUXGhyornei1e2BWwh4PG23BKlvcaGitgnn6lrgdHtwqrqxm77N91MqAJ1ahTCtChE6FSJ1GkTqVIjUqdEnou1Kt9iIttuPxERoEKnTSDerjdKrob7iCjgF2k7pqZQKqJXKtqvpQihAMeQQEREB0GtU0GtUiDfoMaQD73O5PZduBdKMJqfr8twi6Z5pAi5327yiVrenbQ6S24NWl4DL0zb/qLapFTWNTtRemsjd0uqG59LI03enI3kE0Hxp4nhNIwB0bi2l61EpFdCqvFe2tY1KaVXKy6NKl1bxVquU0KgU0oKU3j97F6b0/vnXdw+RbdVuhhwiIqIuUKuU110Ru7u4LwUkR+vlydlNTrd0E9pGhwv1La2oaWzFxQYHLjY6Ud3gQF1TKxocLtS3tG2/1tVv1/qsZk9biOoOs++6sVv20xkMOURERAGu7Z5nqku36uj8qIh3JAloWw4AaJu35BYCbrfwuSruyqvdHK0eaWTJW+sdmfI+nK62USvp+aU/R+jku70IQw4REVEv0XZaSe4ueg7X3yYiIqKQxJBDREREIYkhh4iIiEISQw4RERGFJIYcIiIiCkkMOURERBSSGHKIiIgoJAV9yFmxYgUGDhwIvV6PzMxM7NmzR+6WiIiIKAAEdchZu3YtcnNzsXTpUuzfvx8jR46ExWJBVVWV3K0RERGRzII65Pzxj3/EY489hpkzZyItLQ1vvvkmwsPD8de//lXu1oiIiEhmQRtynE4niouLkZWVJb2mVCqRlZWFoqKia77H4XDAbrf7PIiIiCg0BW3Iqa6uhtvtRkJCgs/rCQkJsFqt13xPXl4ejEaj9EhOTu6JVomIiEgGQRtyOmPx4sWw2WzSo6KiQu6WiIiIyE+C9i7kcXFxUKlUqKys9Hm9srISJpPpmu/R6XTQ6XTSc3HpPvM8bUVERBQ8vL/b3t/x6wnakKPVapGRkYHCwkJMmjQJAODxeFBYWIi5c+e2ax/19fUAwNNWREREQai+vh5Go/G624M25ABAbm4uZsyYgbFjx2LcuHF47bXX0NjYiJkzZ7br/YmJiaioqEBUVBQUCkW39WW325GcnIyKigoYDIZu2y9djce65/BY9xwe657F491zuutYCyFQX1+PxMTE760L6pAzdepUXLhwAUuWLIHVasWoUaOwefPmqyYjX49SqURSUpLf+jMYDPw/TA/hse45PNY9h8e6Z/F495zuONbfN4LjFdQhBwDmzp3b7tNTRERE1Hv0qquriIiIqPdgyPEDnU6HpUuX+lzJRf7BY91zeKx7Do91z+Lx7jk9fawV4oeuvyIiIiIKQhzJISIiopDEkENEREQhiSGHiIiIQhJDDhEREYUkhhw/WLFiBQYOHAi9Xo/MzEzs2bNH7paCWl5eHm655RZERUUhPj4ekyZNQllZmU9NS0sLcnJyEBsbi8jISEyZMuWq+5pRx7300ktQKBSYP3++9BqPdfc6e/YsfvGLXyA2NhZhYWFIT0/Hvn37pO1CCCxZsgT9+vVDWFgYsrKycOLECRk7Dk5utxvPPvssBg0ahLCwMNx44434/e9/73PvIx7rztmxYwd+8pOfIDExEQqFAh9//LHP9vYc15qaGkyfPh0GgwHR0dGYNWsWGhoaut6coG61Zs0aodVqxV//+ldx+PBh8dhjj4no6GhRWVkpd2tBy2KxiHfeeUccOnRIlJSUiPvuu0+kpKSIhoYGqWb27NkiOTlZFBYWin379olbb71V3HbbbTJ2Hfz27NkjBg4cKEaMGCHmzZsnvc5j3X1qamrEgAEDxC9/+Uuxe/ducfLkSbFlyxbx9ddfSzUvvfSSMBqN4uOPPxZfffWV+OlPfyoGDRokmpubZew8+LzwwgsiNjZWbNiwQZw6dUrk5+eLyMhIsXz5cqmGx7pzNm3aJJ5++mnx4YcfCgDio48+8tnenuN6zz33iJEjR4pdu3aJf/7zn2Lw4MFi2rRpXe6NIaebjRs3TuTk5EjP3W63SExMFHl5eTJ2FVqqqqoEALF9+3YhhBB1dXVCo9GI/Px8qebo0aMCgCgqKpKrzaBWX18vhgwZIgoKCsRdd90lhRwe6+715JNPivHjx193u8fjESaTSbz88svSa3V1dUKn04kPPvigJ1oMGdnZ2eKRRx7xeW3y5Mli+vTpQgge6+7y3ZDTnuN65MgRAUDs3btXqvn000+FQqEQZ8+e7VI/PF3VjZxOJ4qLi5GVlSW9plQqkZWVhaKiIhk7Cy02mw0AEBMTAwAoLi5Ga2urz3FPTU1FSkoKj3sn5eTkIDs72+eYAjzW3e2TTz7B2LFj8cADDyA+Ph6jR4/GW2+9JW0/deoUrFarz/E2Go3IzMzk8e6g2267DYWFhTh+/DgA4KuvvsIXX3yBe++9FwCPtb+057gWFRUhOjoaY8eOlWqysrKgVCqxe/fuLn1+0N+7KpBUV1fD7XZfdYPQhIQEHDt2TKauQovH48H8+fNx++23Y/jw4QAAq9UKrVaL6Ohon9qEhARYrVYZugxua9aswf79+7F3796rtvFYd6+TJ09i5cqVyM3NxX/+539i7969+PWvfw2tVosZM2ZIx/Raf6fweHfMU089BbvdjtTUVKhUKrjdbrzwwguYPn06APBY+0l7jqvVakV8fLzPdrVajZiYmC4fe4YcCio5OTk4dOgQvvjiC7lbCUkVFRWYN28eCgoKoNfr5W4n5Hk8HowdOxYvvvgiAGD06NE4dOgQ3nzzTcyYMUPm7kLLunXr8N577+H999/HsGHDUFJSgvnz5yMxMZHHOoTxdFU3iouLg0qluupKk8rKSphMJpm6Ch1z587Fhg0b8PnnnyMpKUl63WQywel0oq6uzqeex73jiouLUVVVhTFjxkCtVkOtVmP79u14/fXXoVarkZCQwGPdjfr164e0tDSf126++WaUl5cDgHRM+XdK1y1cuBBPPfUUHnzwQaSnp+Ohhx7CggULkJeXB4DH2l/ac1xNJhOqqqp8trtcLtTU1HT52DPkdCOtVouMjAwUFhZKr3k8HhQWFsJsNsvYWXATQmDu3Ln46KOPsHXrVgwaNMhne0ZGBjQajc9xLysrQ3l5OY97B919990oLS1FSUmJ9Bg7diymT58u/ZnHuvvcfvvtVy2HcPz4cQwYMAAAMGjQIJhMJp/jbbfbsXv3bh7vDmpqaoJS6fuTp1Kp4PF4APBY+0t7jqvZbEZdXR2Ki4ulmq1bt8Lj8SAzM7NrDXRp2jJdZc2aNUKn04nVq1eLI0eOiMcff1xER0cLq9Uqd2tBa86cOcJoNIpt27aJ8+fPS4+mpiapZvbs2SIlJUVs3bpV7Nu3T5jNZmE2m2XsOnRceXWVEDzW3WnPnj1CrVaLF154QZw4cUK89957Ijw8XPztb3+Tal566SURHR0t/u///k8cPHhQ/OxnP+NlzZ0wY8YM0b9/f+kS8g8//FDExcWJRYsWSTU81p1TX18vDhw4IA4cOCAAiD/+8Y/iwIED4ttvvxVCtO+43nPPPWL06NFi9+7d4osvvhBDhgzhJeSB6k9/+pNISUkRWq1WjBs3TuzatUvuloIagGs+3nnnHammublZ/OpXvxJ9+vQR4eHh4v777xfnz5+Xr+kQ8t2Qw2PdvdavXy+GDx8udDqdSE1NFatWrfLZ7vF4xLPPPisSEhKETqcTd999tygrK5Op2+Blt9vFvHnzREpKitDr9eKGG24QTz/9tHA4HFINj3XnfP7559f8O3rGjBlCiPYd14sXL4pp06aJyMhIYTAYxMyZM0V9fX2Xe1MIccVyj0REREQhgnNyiIiIKCQx5BAREVFIYsghIiKikMSQQ0RERCGJIYeIiIhCEkMOERERhSSGHCIiIgpJDDlEREQUkhhyiIiIKCQx5BAREVFIYsghIiKikMSQQ0RERCHp/wcdaRD5jNvATAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон Хипса -- обратная сторона закона Ципфа. Он описывает, что чем больше корпус, тем меньше новых слов добавляется с добавлением новых текстов. В какой-то момент корпус насыщается."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1.\n",
    "\n",
    "**Задание**: обучите три классификатора: \n",
    "\n",
    "1) на токенах с высокой частотой \n",
    "\n",
    "2) на токенах со средней частотой \n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Создадим корпус по тренировочным данным и отсортируем по частотам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2152311\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['reg_biryukova',\n",
       " 'портрет',\n",
       " 'который',\n",
       " 'я',\n",
       " 'рисовала',\n",
       " 'еще',\n",
       " 'летом',\n",
       " 'с',\n",
       " 'фотки',\n",
       " 'какой-то']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in x_train for token in word_tokenize(tweet) if token not in punctuation]\n",
    "print(len(corpus))\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('не', 51978),\n",
       " ('и', 41337),\n",
       " ('в', 39724),\n",
       " ('я', 39595),\n",
       " ('RT', 28558),\n",
       " ('на', 26672),\n",
       " ('http', 24893),\n",
       " ('что', 23686),\n",
       " ('с', 20441),\n",
       " ('а', 20091)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted = sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "first_100_freqs = [freq for word, freq in freq_dict_sorted[:100]]\n",
    "plt.plot(first_100_freqs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим частоты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freqs = [freq for word, freq in freq_dict_sorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Найдем такие пороги, чтобы модели встречали одинаковое количество раз слова из своих словарей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n",
      "3075\n"
     ]
    }
   ],
   "source": [
    "sum_freqs = 0\n",
    "flag_1 = True\n",
    "for i in range(len(freqs)):\n",
    "    sum_freqs+=freqs[i]\n",
    "    if flag_1:\n",
    "        if sum_freqs>=(sum(freqs)*1/3):\n",
    "            threshold_token_1 = i\n",
    "            flag_1 = False\n",
    "    if sum_freqs>=(sum(freqs)*2/3):\n",
    "        threshold_token_2 = i\n",
    "        break\n",
    "print(threshold_token_1)\n",
    "print(threshold_token_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на крайние токены:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Не', 2871)\n",
      "('всякий', 57)\n"
     ]
    }
   ],
   "source": [
    "print(freq_dict_sorted[threshold_token_1])\n",
    "print(freq_dict_sorted[threshold_token_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получим слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_sorted_words = [word for word, freq in freq_dict_sorted]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1) на токенах с высокой частотой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "high_freq_tokens = freq_sorted_words[:threshold_token_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['не', 'и', 'в', 'я', 'RT', 'на', 'http', 'что', 'с', 'а']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "high_freq_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.57      0.62      0.59     25474\n",
      "    positive       0.67      0.61      0.64     31235\n",
      "\n",
      "    accuracy                           0.62     56709\n",
      "   macro avg       0.62      0.62      0.62     56709\n",
      "weighted avg       0.62      0.62      0.62     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=list(punctuation), vocabulary=high_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2) на токенах со средней частотой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "medium_freq_tokens = freq_sorted_words[threshold_token_1:threshold_token_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Не', 'всё', 'сейчас', 'буду', '....', 'Как', 'У', 'знаю', 'тут', 'без']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medium_freq_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.64      0.71      0.67     24996\n",
      "    positive       0.75      0.68      0.71     31713\n",
      "\n",
      "    accuracy                           0.69     56709\n",
      "   macro avg       0.69      0.70      0.69     56709\n",
      "weighted avg       0.70      0.69      0.69     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=list(punctuation), vocabulary=medium_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) на токенах с низкой частотой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "low_freq_tokens = freq_sorted_words[threshold_token_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['всякий',\n",
       " 'оставить',\n",
       " 'зная',\n",
       " 'Последняя',\n",
       " '45',\n",
       " 'СЕГОДНЯ',\n",
       " 'реву',\n",
       " 'останусь',\n",
       " 'мешает',\n",
       " 'пиццу']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_freq_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.67      0.71     32379\n",
      "    positive       0.62      0.73      0.67     24330\n",
      "\n",
      "    accuracy                           0.69     56709\n",
      "   macro avg       0.70      0.70      0.69     56709\n",
      "weighted avg       0.71      0.69      0.70     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=list(punctuation), vocabulary=low_freq_tokens)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод:\n",
    "1). В пером случае у нас маленький словарь и большинство слов, это шум, который не несёт большой смысловой нагрузки  \n",
    "2). Во-второй интервал вошли как шум, так и слова, имеющие более глубокий смысл. Метрики уже лучше. Но negative немного уступает positive.  \n",
    "3). В третий интервал слова шум уже не попали. Accuracy выше, чем в предыдущих интервалах. Но здесь наоборот, класс positive предсказывается хуже negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## О важности эксплоративного анализа\n",
    "\n",
    "Но иногда пунктуация бывает и не шумом -- главное отталкиваться от задачи. Что будет если вообще не убирать пунктуацию?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      1.00      1.00     28014\n",
      "    positive       1.00      1.00      1.00     28695\n",
      "\n",
      "    accuracy                           1.00     56709\n",
      "   macro avg       1.00      1.00      1.00     56709\n",
      "weighted avg       1.00      1.00      1.00     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=word_tokenize)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шок! Стоило оставить пунктуацию - и все метрики равны 1. Как это получилось? Среди неё были очень значимые токены (как вы думаете, какие?). Найдите фичи с самыми большими коэффициентами:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2.\n",
    "\n",
    "Найти фичи с наибольшей значимостью, и вывести их"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "О том насколько влияют токены нам скажут их веса, чем они больше в абсолютном значении, тем большее влияние у токена"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-0.0024840910069232535, 0),\n",
       " (0.37614198282656336, 1),\n",
       " (-0.06780228496619159, 2),\n",
       " (1.1918633095203615, 3),\n",
       " (-0.2486369602924179, 4)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_coef = list(zip(clf.coef_[0], range(len(clf.coef_[0]))))\n",
    "dict_coef[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-59.65181690013905, 7),\n",
       " (58.44868075226079, 8),\n",
       " (26.902344111633397, 43457),\n",
       " (-11.323374960749085, 101470),\n",
       " (-10.811896767830275, 180132)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_coef_sorted = sorted(dict_coef, key=(lambda x: -abs(x[0])))\n",
    "dict_coef_sorted[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('@', 29513),\n",
       " ('reg_biryukova', 83260),\n",
       " ('портрет', 201102),\n",
       " (',', 100),\n",
       " ('который', 156761)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vec.vocabulary_.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29513, '@'),\n",
       " (83260, 'reg_biryukova'),\n",
       " (201102, 'портрет'),\n",
       " (100, ','),\n",
       " (156761, 'который')]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_vocabulary_reverse = {y:x for x, y in vec.vocabulary_.items()}\n",
    "list(vec_vocabulary_reverse.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(', ')', 'd', '|', 'о_о', 'dd', '^_^', '-/', 'o_o', 'ddd']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_sorted = [vec_vocabulary_reverse[y] for x,y in dict_coef_sorted]\n",
    "vocabulary_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.85      0.92     32914\n",
      "    positive       0.83      1.00      0.91     23795\n",
      "\n",
      "    accuracy                           0.91     56709\n",
      "   macro avg       0.92      0.93      0.91     56709\n",
      "weighted avg       0.93      0.91      0.92     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cool_token = ')'\n",
    "pred = ['positive' if cool_token in tweet else 'negative' for tweet in x_test]\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Вывод:**  \n",
    "В задаче Sentiment analysis огромную роль играют эмотиконы, а значит и символы(знаки пунктуации) из которых их часто состоявляют"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Символьные n-граммы\n",
    "\n",
    "Теперь в качестве фичей используем, например, униграммы символов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.99      1.00      0.99     27966\n",
      "    positive       1.00      0.99      0.99     28743\n",
      "\n",
      "    accuracy                           0.99     56709\n",
      "   macro avg       0.99      0.99      0.99     56709\n",
      "weighted avg       0.99      0.99      0.99     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(analyzer='char', ngram_range=(1, 1))\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В общем-то, теперь уже понятно, почему на этих данных здесь 1 (или почти 1). Так или иначе, на символах классифицировать тоже можно: для некоторых задач (например, для определения языка) фичи-символьные n-граммы решительно рулят.\n",
    "\n",
    "Ещё одна замечательная особенность фичей-символов: токенизация и лемматизация не нужна, можно использовать такой подход для языков, у которых нет готовых анализаторов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1). сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.80      0.77      0.78     29234\n",
      "    positive       0.76      0.80      0.78     27475\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = CountVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.78      0.77     27670\n",
      "    positive       0.79      0.78      0.78     29039\n",
      "\n",
      "    accuracy                           0.78     56709\n",
      "   macro avg       0.78      0.78      0.78     56709\n",
      "weighted avg       0.78      0.78      0.78     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = TfidfVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=noise)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hashing_n_features = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.61      0.59      0.60     28931\n",
      "    positive       0.59      0.61      0.60     27778\n",
      "\n",
      "    accuracy                           0.60     56709\n",
      "   macro avg       0.60      0.60      0.60     56709\n",
      "weighted avg       0.60      0.60      0.60     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vec = HashingVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=noise, n_features=hashing_n_features)\n",
    "bow = vec.fit_transform(x_train)\n",
    "clf = LogisticRegression(random_state=42)\n",
    "clf.fit(bow, y_train)\n",
    "pred = clf.predict(vec.transform(x_test))\n",
    "print(classification_report(pred, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Предобработка данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1503624\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['reg_biryukova', 'портрет', 'который', 'рисовала', 'летом']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [token for tweet in x_train for token in word_tokenize(tweet) if token not in noise]\n",
    "print(len(corpus))\n",
    "corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RT', 28558),\n",
       " ('http', 24893),\n",
       " ('...', 16875),\n",
       " ('D', 12482),\n",
       " ('это', 12360),\n",
       " (\"''\", 9338),\n",
       " ('Я', 9279),\n",
       " ('``', 8616),\n",
       " ('..', 8514),\n",
       " ('А', 6478)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_dict = Counter(corpus)\n",
    "freq_dict_sorted= sorted(freq_dict.items(), key=lambda x: -x[1])\n",
    "list(freq_dict_sorted)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288501"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size = len(freq_dict)\n",
    "VOCABULARY_SIZE = vocabulary_size\n",
    "VOCABULARY_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RT', 'http', '...', 'D', 'это']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_n_words = [word for word, freq in freq_dict_sorted[:VOCABULARY_SIZE]]\n",
    "top_n_words[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('RT', 1), ('http', 2), ('...', 3), ('D', 4), ('это', 5)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {y:x for x,y in enumerate(top_n_words, start=1)}\n",
    "list(vocab.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86125              [91570, 8024, 127, 9326, 893, 369, 340]\n",
       "86057    [7, 8436, 3, 1528, 14254, 3, 95, 31411, 9, 315...\n",
       "22308    [218, 786, 130, 1221, 623, 10, 26, 73, 2321, 290]\n",
       "67698            [1, 31412, 17284, 706, 1056, 1389, 55521]\n",
       "90046                          [1, 55522, 326, 107, 13092]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nn = x_train.apply(lambda text: [vocab.get(word, 0) for word in nltk.word_tokenize(text) if word not in noise])\n",
    "x_test_nn = x_test.apply(lambda text: [vocab.get(word, 0) for word in nltk.word_tokenize(text) if word not in noise])\n",
    "x_train_nn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = x_train_nn.apply(lambda txt: len(txt)).max()\n",
    "MAX_LEN = max_len\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86125    [91570, 8024, 127, 9326, 893, 369, 340, 0, 0, ...\n",
       "86057    [7, 8436, 3, 1528, 14254, 3, 95, 31411, 9, 315...\n",
       "22308    [218, 786, 130, 1221, 623, 10, 26, 73, 2321, 2...\n",
       "67698    [1, 31412, 17284, 706, 1056, 1389, 55521, 0, 0...\n",
       "90046    [1, 55522, 326, 107, 13092, 0, 0, 0, 0, 0, 0, ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nn = x_train_nn.apply(lambda x: x+[0]*(MAX_LEN-len(x)))\n",
    "x_test_nn = x_test_nn.apply(lambda x: x+[0]*(MAX_LEN-len(x)))\n",
    "x_train_nn[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([91570,  8024,   127,  9326,   893,   369,   340,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "           0,     0,     0,     0])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_nn_array = np.array([j for j in [i for i in x_train_nn]])\n",
    "x_test_nn_array = np.array([j for j in [i for i in x_test_nn]])\n",
    "x_train_nn_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86125    1\n",
       "86057    0\n",
       "22308    1\n",
       "67698    0\n",
       "90046    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_nn = y_train.apply(lambda x: 1 if x=='positive' else 0)\n",
    "y_test_nn = y_test.apply(lambda x: 1 if x=='positive' else 0)\n",
    "y_train_nn[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 07:57:10.416540: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-08 07:57:10.453269: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-04-08 07:57:10.453639: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-08 07:57:11.234772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, Conv1D, GlobalAveragePooling1D, BatchNormalization, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_dim = 32\n",
    "hidden_dim = 16\n",
    "dropout = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-08 07:57:11.734216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-04-08 07:57:11.734704: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(VOCABULARY_SIZE+1, embedding_dim), # VOCABULARY_SIZE+1 так как еще 0, который показывает где нет слова\n",
    "    BatchNormalization(),\n",
    "    Dropout(dropout),\n",
    "\n",
    "    GlobalAveragePooling1D(),\n",
    "\n",
    "    Dense(hidden_dim, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "1330/1330 [==============================] - 132s 99ms/step - loss: 0.5004 - accuracy: 0.7435\n",
      "Epoch 2/2\n",
      "1330/1330 [==============================] - 132s 99ms/step - loss: 0.2746 - accuracy: 0.8826\n"
     ]
    }
   ],
   "source": [
    "hh = model.fit(x_train_nn_array, y_train_nn, epochs=2, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1773/1773 [==============================] - 1s 660us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6041726 ],\n",
       "       [0.40202722],\n",
       "       [0.13869362],\n",
       "       [0.67023736],\n",
       "       [0.1535489 ]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_preds = model.predict(x_test_nn_array)\n",
    "nn_preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как классы сбалансированны, то порог можно взять 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_preds_bin = (nn_preds > threshold).astype(int)\n",
    "nn_preds_bin[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74     24168\n",
      "           1       0.83      0.73      0.78     32541\n",
      "\n",
      "    accuracy                           0.76     56709\n",
      "   macro avg       0.76      0.77      0.76     56709\n",
      "weighted avg       0.77      0.76      0.76     56709\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nn_preds_bin, y_test_nn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод:**  \n",
    "Строить нейронную сеть и препроцессить для неё данные долго, еще дольше только подбирать параметры и обучать её, а результат считай такой же, но это я не использовал свёртки и res блоки.\n",
    "\n",
    "HashingVectorizer быстрее остальных, но результаты хуже остальных, дальше буду подбирать количество признаков.\n",
    "\n",
    "Результаты CountVectorizer и TfidfVectorizer почти одинаковые, но у TfidfVectorizer они более уравновешанные относительно классов. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2). подобрать оптимальный размер для hashing векторайзера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_features = [10, 100, 1000, 10000, 100000, 500000, 1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_features: 10; acc: 0.5434234424870832; time: 29.412506580352783\n",
      "n_features: 100; acc: 0.5988114761325363; time: 29.4119131565094\n",
      "n_features: 1000; acc: 0.6609709217231833; time: 29.57880663871765\n",
      "n_features: 10000; acc: 0.7285792378634784; time: 30.180861234664917\n",
      "n_features: 100000; acc: 0.7633708935089668; time: 35.03838849067688\n",
      "n_features: 500000; acc: 0.770688955897653; time: 44.67604446411133\n",
      "n_features: 1000000; acc: 0.770688955897653; time: 48.19840860366821\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for features in n_features:\n",
    "  start_time = time.time()\n",
    "  vec = HashingVectorizer(ngram_range=(1, 1), tokenizer=nltk.word_tokenize, stop_words=noise, n_features=features)\n",
    "  bow = vec.fit_transform(x_train)\n",
    "  clf = LogisticRegression(random_state=42)\n",
    "  clf.fit(bow, y_train)\n",
    "  pred = clf.predict(vec.transform(x_test))\n",
    "  acc = (pred == y_test).sum() / len(y_test)\n",
    "  print(f'n_features: {features}; acc: {acc}; time: {time.time()-start_time}')\n",
    "  res.append({'n_features': features, 'acc': acc, 'time': (time.time()-start_time)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Вывод**  \n",
    "Чем больше мы возьмём параметров, тем лучше результат, но тем дольше обучается модель. Но разница по метрикам, например, между n_features = 100 и n_features = 1000 большая, а по времени маленькая, а вот для n_features = 100000 и n_features = 500000, наоборот, разница по метрики маленькая, а вот по времени большая.  \n",
    "Таким образом, оптимальный размер для hashing векторайзера в нашем случае будет n_features = 100000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  3). убедиться что для сетки нет переобучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5317/5317 [==============================] - 3s 612us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.8770349 ],\n",
       "       [0.11014671],\n",
       "       [0.9931741 ],\n",
       "       [0.04926991],\n",
       "       [0.00415495]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_preds = model.predict(x_train_nn_array)\n",
    "nn_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_preds_bin = (nn_preds > threshold).astype(int)\n",
    "nn_preds_bin[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94     77688\n",
      "           1       0.98      0.91      0.95     92437\n",
      "\n",
      "    accuracy                           0.94    170125\n",
      "   macro avg       0.94      0.95      0.94    170125\n",
      "weighted avg       0.95      0.94      0.94    170125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(nn_preds_bin, y_train_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          9232064   \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, None, 32)         128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 32)          0         \n",
      "                                                                 \n",
      " global_average_pooling1d (G  (None, 32)               0         \n",
      " lobalAveragePooling1D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                528       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,232,737\n",
      "Trainable params: 9,232,673\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики на train не равны все 1, что уже хорошо, они конечно больше на 0.2 чем метрики на test, поэтому можно сказать, что небольшое переобучение возможно. Но я и так тренировал всего 2 эпохи, взял маленькое количество нейронов для классификации и использовал batchnorm и dropout(0.2). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

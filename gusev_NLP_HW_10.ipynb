{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0Qjg6vuaHNt"
      },
      "source": [
        "<h1 align='center'>Введение в обработку естественного языка</h1>  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2 align='center'>Урок 8. Рекуррентные нейронные сети RNN LSTM GRU</h2>  "
      ],
      "metadata": {
        "id": "rYUTj2aonXmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3 align='left'>Практическое задание:</h3>  \n",
        "\n",
        "Разобраться с моделькой перевода как она устроена (без механизма внимания), запустить для перевода с русского на английский (при желании можно взять другие пары языков)"
      ],
      "metadata": {
        "id": "nEgAKCXPngRm"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnxXKDjq3jEL"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfodePkj3jEa"
      },
      "source": [
        "## Скачиваем и обрабатываем датасет\n",
        "\n",
        "Мы будем использовать набор языковых данных, предоставленный http://www.manythings.org/anki/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNvjhDyAKk3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40952a2c-ab50-4f28-aa28-6e3738d20606"
      },
      "source": [
        "!wget http://www.manythings.org/anki/rus-eng.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-17 18:35:29--  http://www.manythings.org/anki/rus-eng.zip\n",
            "Resolving www.manythings.org (www.manythings.org)... 173.254.30.110\n",
            "Connecting to www.manythings.org (www.manythings.org)|173.254.30.110|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15460248 (15M) [application/zip]\n",
            "Saving to: ‘rus-eng.zip’\n",
            "\n",
            "rus-eng.zip         100%[===================>]  14.74M  6.38MB/s    in 2.3s    \n",
            "\n",
            "2023-05-17 18:35:32 (6.38 MB/s) - ‘rus-eng.zip’ saved [15460248/15460248]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83bg17Lr-7XK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed2e2c3-65f8-4960-d8ed-b3e14ecfc6f8"
      },
      "source": [
        "!mkdir rus-eng\n",
        "!unzip rus-eng.zip -d rus-eng/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  rus-eng.zip\n",
            "  inflating: rus-eng/rus.txt         \n",
            "  inflating: rus-eng/_about.txt      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o5L92efMMhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3a87e6a-65ea-4c68-a727-4ca64322c2f6"
      },
      "source": [
        "!ls /content/rus-eng/ -lah"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 74M\n",
            "drwxr-xr-x 2 root root 4.0K May 17 18:35 .\n",
            "drwxr-xr-x 1 root root 4.0K May 17 18:35 ..\n",
            "-rw-r--r-- 1 root root 1.5K Apr  2 03:16 _about.txt\n",
            "-rw-r--r-- 1 root root  74M Apr  2 03:16 rus.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRVATYOgJs1b"
      },
      "source": [
        "# Путь к файлу\n",
        "path_to_file = \"/content/rus-eng/rus.txt\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция препроцессинга"
      ],
      "metadata": {
        "id": "iCQneMFQoSqa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rd0jw-eC3jEh"
      },
      "source": [
        "def preprocess_sentence(w):\n",
        "  w = w.lower().strip()\n",
        "\n",
        "  # вставим пробелы между словом и следующими за ним знаками препинания\n",
        "  # например: \"he is a boy.\" => \"he is a boy .\"\n",
        "  # Источник:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
        "  w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n",
        "  w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "  # заменим всё пробелами, кроме (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "  w = re.sub(r\"[^a-zA-Zа-яА-Я?.!,']+\", \" \", w)\n",
        "\n",
        "  w = w.strip()\n",
        "\n",
        "  # добавление начального и конечного токенов в предложение\n",
        "  # так модель будет знать, когда начать и закончить предсказание  \n",
        "  w = '<start> ' + w + ' <end>'\n",
        "  return w"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пример:"
      ],
      "metadata": {
        "id": "bafkIA5XpdUM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yV9lZXQXNbnH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "023a298b-78be-488a-a2c9-d1b20e0fada2"
      },
      "source": [
        "preprocess_sentence(\"I can't go.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<start> i can't go . <end>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHn4Dct23jEm"
      },
      "source": [
        "# 1. Уберём акценты\n",
        "# 2. Вычислим предложения\n",
        "# 3. Вернём пары слов в формате: [ENG, RUS]\n",
        "def create_dataset(path, num_examples):\n",
        "  lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "\n",
        "  word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')[:2]]  for l in lines[:num_examples]]\n",
        "\n",
        "  return zip(*word_pairs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTbSbBz55QtF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c4b02f4-5f7e-48bc-b898-d3460015762e"
      },
      "source": [
        "en, ru = create_dataset(path_to_file, None)\n",
        "print(en[0])\n",
        "print(ru[0])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> go . <end>\n",
            "<start> марш ! <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIOn8RCNDJXG"
      },
      "source": [
        "def tokenize(lang):\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "      filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,\n",
        "                                                         padding='post')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAY9k49G3jE_"
      },
      "source": [
        "def load_dataset(path, num_examples=None):\n",
        "  # creating cleaned input, output pairs\n",
        "  targ_lang, inp_lang = create_dataset(path, num_examples)\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(inp_lang)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(targ_lang)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOi42V79Ydlr"
      },
      "source": [
        "### Limit the size of the dataset to experiment faster (optional)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8j9g9AnIeZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48517214-3df9-4574-ac9a-5cb1ed1fd9f2"
      },
      "source": [
        "len(en), len(ru)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(467119, 467119)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnxC7q-j3jFD"
      },
      "source": [
        "# Попробуем поэкспериментировать с размером набора данных\n",
        "num_examples = 100000\n",
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset(path_to_file, num_examples)\n",
        "\n",
        "# Подсчитаем максимальную длину (max_length) искомого тензора\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QILQkOs3jFG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24734e70-4f90-409d-ef07-775d160e25ff"
      },
      "source": [
        "# Создание обучающих и проверочных наборов с использованием разделения 80 на 20\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "# Посмотрим на их длину\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80000 80000 20000 20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJPmLZGMeD5q"
      },
      "source": [
        "def convert(lang, tensor):\n",
        "  for t in tensor:\n",
        "    if t!=0:\n",
        "      print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXukARTDd7MT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c78d1377-0039-4fea-c975-5755da29a6b2"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\n",
        "convert(inp_lang, input_tensor_train[0])\n",
        "print ()\n",
        "print (\"Target Language; index to word mapping\")\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "19 ----> он\n",
            "38 ----> е\n",
            "115 ----> любит\n",
            "3 ----> .\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "29 ----> he\n",
            "264 ----> loves\n",
            "117 ----> her\n",
            "3 ----> .\n",
            "2 ----> <end>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCLkfv5uO3d"
      },
      "source": [
        "### Создадим tf.data dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqHsArVZ3jFS"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim = 300\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qc6-NK1GtWQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fe5231-d983-4195-d644-7974a7321cef"
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 15]), TensorShape([64, 11]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ2rI24i3jFg"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.enc_units = enc_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                   return_sequences=False,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    \n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state = hidden)\n",
        "    return state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60gSVh05Jl6l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e331de-a92e-4639-ac81-c809f1ef3aa4"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# выборочный ввод\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "# print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yJ_B3mhW3jFk"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.batch_sz = batch_sz\n",
        "    self.dec_units = dec_units\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_initializer='glorot_uniform')\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "\n",
        "    # передача объединенного вектора в GRU\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UY8wko3jFp"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "decoder_sample_x, decoder_sample_h = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden)\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKcypC0AGeLR",
        "outputId": "80fe2776-2c7e-4de5-d96d-275006b7540e"
      },
      "source": [
        "decoder_sample_x.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 7362])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y0HF-zMF_vp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65870a01-f33b-4d03-b77c-679c78d8de3a"
      },
      "source": [
        "decoder_sample_h.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ch_71VbIRfK"
      },
      "source": [
        "## Определим оптимизатор и функцию потерь"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmTHr5iV3jFr"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMVWzzsfNl4e"
      },
      "source": [
        "## Checkpoints (Object-based saving)\n",
        "\n",
        "Промежуточное сохранение результатов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zj8bXQTgNwrF"
      },
      "source": [
        "checkpoint_dir = './training_nmt_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC9ArXSsVfqn"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    # Teacher forcing - ввод таргета в качестве следующего входного сигнала\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      # проброс enc_output в decoder\n",
        "      predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      # использование teacher forcing\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddefjBMa3jF0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1e0595e-1eb1-48ae-992c-40f354b8b88d"
      },
      "source": [
        "EPOCHS = 15\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                   batch,\n",
        "                                                   batch_loss.numpy()))\n",
        "  # сохраняем (checkpoint) модель каждые 2 эпохи\n",
        "  if (epoch + 1) % 2 == 0:\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "  print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                      total_loss / steps_per_epoch))\n",
        "  print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 4.7179\n",
            "Epoch 1 Batch 100 Loss 2.0827\n",
            "Epoch 1 Batch 200 Loss 1.7246\n",
            "Epoch 1 Batch 300 Loss 1.6945\n",
            "Epoch 1 Batch 400 Loss 1.5131\n",
            "Epoch 1 Batch 500 Loss 1.4816\n",
            "Epoch 1 Batch 600 Loss 1.3846\n",
            "Epoch 1 Batch 700 Loss 1.4122\n",
            "Epoch 1 Batch 800 Loss 1.1806\n",
            "Epoch 1 Batch 900 Loss 1.1584\n",
            "Epoch 1 Batch 1000 Loss 1.1129\n",
            "Epoch 1 Batch 1100 Loss 1.1264\n",
            "Epoch 1 Batch 1200 Loss 1.1389\n",
            "Epoch 1 Loss 1.4754\n",
            "Time taken for 1 epoch 85.10304570198059 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.9189\n",
            "Epoch 2 Batch 100 Loss 0.9751\n",
            "Epoch 2 Batch 200 Loss 0.9108\n",
            "Epoch 2 Batch 300 Loss 0.9498\n",
            "Epoch 2 Batch 400 Loss 0.9561\n",
            "Epoch 2 Batch 500 Loss 0.8612\n",
            "Epoch 2 Batch 600 Loss 0.8383\n",
            "Epoch 2 Batch 700 Loss 0.8623\n",
            "Epoch 2 Batch 800 Loss 0.8502\n",
            "Epoch 2 Batch 900 Loss 0.8060\n",
            "Epoch 2 Batch 1000 Loss 0.7457\n",
            "Epoch 2 Batch 1100 Loss 0.6537\n",
            "Epoch 2 Batch 1200 Loss 0.7273\n",
            "Epoch 2 Loss 0.8253\n",
            "Time taken for 1 epoch 55.40283751487732 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.5143\n",
            "Epoch 3 Batch 100 Loss 0.5870\n",
            "Epoch 3 Batch 200 Loss 0.5028\n",
            "Epoch 3 Batch 300 Loss 0.4977\n",
            "Epoch 3 Batch 400 Loss 0.5433\n",
            "Epoch 3 Batch 500 Loss 0.4214\n",
            "Epoch 3 Batch 600 Loss 0.4099\n",
            "Epoch 3 Batch 700 Loss 0.3616\n",
            "Epoch 3 Batch 800 Loss 0.4871\n",
            "Epoch 3 Batch 900 Loss 0.4082\n",
            "Epoch 3 Batch 1000 Loss 0.4660\n",
            "Epoch 3 Batch 1100 Loss 0.3913\n",
            "Epoch 3 Batch 1200 Loss 0.3809\n",
            "Epoch 3 Loss 0.4761\n",
            "Time taken for 1 epoch 54.16253924369812 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.3032\n",
            "Epoch 4 Batch 100 Loss 0.3192\n",
            "Epoch 4 Batch 200 Loss 0.2962\n",
            "Epoch 4 Batch 300 Loss 0.2692\n",
            "Epoch 4 Batch 400 Loss 0.2869\n",
            "Epoch 4 Batch 500 Loss 0.2829\n",
            "Epoch 4 Batch 600 Loss 0.2910\n",
            "Epoch 4 Batch 700 Loss 0.3266\n",
            "Epoch 4 Batch 800 Loss 0.2957\n",
            "Epoch 4 Batch 900 Loss 0.3101\n",
            "Epoch 4 Batch 1000 Loss 0.2981\n",
            "Epoch 4 Batch 1100 Loss 0.2789\n",
            "Epoch 4 Batch 1200 Loss 0.2741\n",
            "Epoch 4 Loss 0.2803\n",
            "Time taken for 1 epoch 54.74902844429016 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.1591\n",
            "Epoch 5 Batch 100 Loss 0.1186\n",
            "Epoch 5 Batch 200 Loss 0.1989\n",
            "Epoch 5 Batch 300 Loss 0.2239\n",
            "Epoch 5 Batch 400 Loss 0.1982\n",
            "Epoch 5 Batch 500 Loss 0.1459\n",
            "Epoch 5 Batch 600 Loss 0.2233\n",
            "Epoch 5 Batch 700 Loss 0.2406\n",
            "Epoch 5 Batch 800 Loss 0.1703\n",
            "Epoch 5 Batch 900 Loss 0.1699\n",
            "Epoch 5 Batch 1000 Loss 0.2004\n",
            "Epoch 5 Batch 1100 Loss 0.2017\n",
            "Epoch 5 Batch 1200 Loss 0.1915\n",
            "Epoch 5 Loss 0.1822\n",
            "Time taken for 1 epoch 54.715824365615845 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.1118\n",
            "Epoch 6 Batch 100 Loss 0.1170\n",
            "Epoch 6 Batch 200 Loss 0.1153\n",
            "Epoch 6 Batch 300 Loss 0.1369\n",
            "Epoch 6 Batch 400 Loss 0.0797\n",
            "Epoch 6 Batch 500 Loss 0.1194\n",
            "Epoch 6 Batch 600 Loss 0.1269\n",
            "Epoch 6 Batch 700 Loss 0.1377\n",
            "Epoch 6 Batch 800 Loss 0.1435\n",
            "Epoch 6 Batch 900 Loss 0.2044\n",
            "Epoch 6 Batch 1000 Loss 0.1098\n",
            "Epoch 6 Batch 1100 Loss 0.1613\n",
            "Epoch 6 Batch 1200 Loss 0.1324\n",
            "Epoch 6 Loss 0.1331\n",
            "Time taken for 1 epoch 54.72522687911987 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0912\n",
            "Epoch 7 Batch 100 Loss 0.1327\n",
            "Epoch 7 Batch 200 Loss 0.0497\n",
            "Epoch 7 Batch 300 Loss 0.1155\n",
            "Epoch 7 Batch 400 Loss 0.1034\n",
            "Epoch 7 Batch 500 Loss 0.1050\n",
            "Epoch 7 Batch 600 Loss 0.1043\n",
            "Epoch 7 Batch 700 Loss 0.1119\n",
            "Epoch 7 Batch 800 Loss 0.1326\n",
            "Epoch 7 Batch 900 Loss 0.1201\n",
            "Epoch 7 Batch 1000 Loss 0.1302\n",
            "Epoch 7 Batch 1100 Loss 0.1185\n",
            "Epoch 7 Batch 1200 Loss 0.1432\n",
            "Epoch 7 Loss 0.1087\n",
            "Time taken for 1 epoch 54.03692007064819 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0593\n",
            "Epoch 8 Batch 100 Loss 0.0676\n",
            "Epoch 8 Batch 200 Loss 0.0803\n",
            "Epoch 8 Batch 300 Loss 0.1082\n",
            "Epoch 8 Batch 400 Loss 0.1050\n",
            "Epoch 8 Batch 500 Loss 0.0889\n",
            "Epoch 8 Batch 600 Loss 0.0892\n",
            "Epoch 8 Batch 700 Loss 0.0619\n",
            "Epoch 8 Batch 800 Loss 0.0912\n",
            "Epoch 8 Batch 900 Loss 0.1222\n",
            "Epoch 8 Batch 1000 Loss 0.1261\n",
            "Epoch 8 Batch 1100 Loss 0.1077\n",
            "Epoch 8 Batch 1200 Loss 0.0856\n",
            "Epoch 8 Loss 0.0947\n",
            "Time taken for 1 epoch 59.571961879730225 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0833\n",
            "Epoch 9 Batch 100 Loss 0.0624\n",
            "Epoch 9 Batch 200 Loss 0.0777\n",
            "Epoch 9 Batch 300 Loss 0.0668\n",
            "Epoch 9 Batch 400 Loss 0.0696\n",
            "Epoch 9 Batch 500 Loss 0.0686\n",
            "Epoch 9 Batch 600 Loss 0.0580\n",
            "Epoch 9 Batch 700 Loss 0.0757\n",
            "Epoch 9 Batch 800 Loss 0.0997\n",
            "Epoch 9 Batch 900 Loss 0.0751\n",
            "Epoch 9 Batch 1000 Loss 0.0952\n",
            "Epoch 9 Batch 1100 Loss 0.1058\n",
            "Epoch 9 Batch 1200 Loss 0.1028\n",
            "Epoch 9 Loss 0.0873\n",
            "Time taken for 1 epoch 54.233718395233154 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0783\n",
            "Epoch 10 Batch 100 Loss 0.0617\n",
            "Epoch 10 Batch 200 Loss 0.0810\n",
            "Epoch 10 Batch 300 Loss 0.0819\n",
            "Epoch 10 Batch 400 Loss 0.0827\n",
            "Epoch 10 Batch 500 Loss 0.0801\n",
            "Epoch 10 Batch 600 Loss 0.0666\n",
            "Epoch 10 Batch 700 Loss 0.0729\n",
            "Epoch 10 Batch 800 Loss 0.1343\n",
            "Epoch 10 Batch 900 Loss 0.0812\n",
            "Epoch 10 Batch 1000 Loss 0.0800\n",
            "Epoch 10 Batch 1100 Loss 0.0747\n",
            "Epoch 10 Batch 1200 Loss 0.0761\n",
            "Epoch 10 Loss 0.0819\n",
            "Time taken for 1 epoch 56.9181854724884 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.0764\n",
            "Epoch 11 Batch 100 Loss 0.0610\n",
            "Epoch 11 Batch 200 Loss 0.0528\n",
            "Epoch 11 Batch 300 Loss 0.0523\n",
            "Epoch 11 Batch 400 Loss 0.0700\n",
            "Epoch 11 Batch 500 Loss 0.0798\n",
            "Epoch 11 Batch 600 Loss 0.0991\n",
            "Epoch 11 Batch 700 Loss 0.0724\n",
            "Epoch 11 Batch 800 Loss 0.1355\n",
            "Epoch 11 Batch 900 Loss 0.0839\n",
            "Epoch 11 Batch 1000 Loss 0.0806\n",
            "Epoch 11 Batch 1100 Loss 0.0596\n",
            "Epoch 11 Batch 1200 Loss 0.0729\n",
            "Epoch 11 Loss 0.0779\n",
            "Time taken for 1 epoch 54.18982410430908 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.0792\n",
            "Epoch 12 Batch 100 Loss 0.0595\n",
            "Epoch 12 Batch 200 Loss 0.0653\n",
            "Epoch 12 Batch 300 Loss 0.0766\n",
            "Epoch 12 Batch 400 Loss 0.0743\n",
            "Epoch 12 Batch 500 Loss 0.0611\n",
            "Epoch 12 Batch 600 Loss 0.0579\n",
            "Epoch 12 Batch 700 Loss 0.1070\n",
            "Epoch 12 Batch 800 Loss 0.1231\n",
            "Epoch 12 Batch 900 Loss 0.0783\n",
            "Epoch 12 Batch 1000 Loss 0.0845\n",
            "Epoch 12 Batch 1100 Loss 0.0832\n",
            "Epoch 12 Batch 1200 Loss 0.0746\n",
            "Epoch 12 Loss 0.0753\n",
            "Time taken for 1 epoch 54.712398529052734 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.0715\n",
            "Epoch 13 Batch 100 Loss 0.0307\n",
            "Epoch 13 Batch 200 Loss 0.0844\n",
            "Epoch 13 Batch 300 Loss 0.0479\n",
            "Epoch 13 Batch 400 Loss 0.0499\n",
            "Epoch 13 Batch 500 Loss 0.1021\n",
            "Epoch 13 Batch 600 Loss 0.0959\n",
            "Epoch 13 Batch 700 Loss 0.0788\n",
            "Epoch 13 Batch 800 Loss 0.0452\n",
            "Epoch 13 Batch 900 Loss 0.0532\n",
            "Epoch 13 Batch 1000 Loss 0.0829\n",
            "Epoch 13 Batch 1100 Loss 0.1118\n",
            "Epoch 13 Batch 1200 Loss 0.0917\n",
            "Epoch 13 Loss 0.0729\n",
            "Time taken for 1 epoch 53.90760612487793 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.0625\n",
            "Epoch 14 Batch 100 Loss 0.0327\n",
            "Epoch 14 Batch 200 Loss 0.0428\n",
            "Epoch 14 Batch 300 Loss 0.1218\n",
            "Epoch 14 Batch 400 Loss 0.0516\n",
            "Epoch 14 Batch 500 Loss 0.0648\n",
            "Epoch 14 Batch 600 Loss 0.1149\n",
            "Epoch 14 Batch 700 Loss 0.0779\n",
            "Epoch 14 Batch 800 Loss 0.0900\n",
            "Epoch 14 Batch 900 Loss 0.0769\n",
            "Epoch 14 Batch 1000 Loss 0.1116\n",
            "Epoch 14 Batch 1100 Loss 0.1035\n",
            "Epoch 14 Batch 1200 Loss 0.0865\n",
            "Epoch 14 Loss 0.0705\n",
            "Time taken for 1 epoch 58.29132533073425 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.0793\n",
            "Epoch 15 Batch 100 Loss 0.0672\n",
            "Epoch 15 Batch 200 Loss 0.0640\n",
            "Epoch 15 Batch 300 Loss 0.0646\n",
            "Epoch 15 Batch 400 Loss 0.0348\n",
            "Epoch 15 Batch 500 Loss 0.0426\n",
            "Epoch 15 Batch 600 Loss 0.0809\n",
            "Epoch 15 Batch 700 Loss 0.0572\n",
            "Epoch 15 Batch 800 Loss 0.0659\n",
            "Epoch 15 Batch 900 Loss 0.0930\n",
            "Epoch 15 Batch 1000 Loss 0.0613\n",
            "Epoch 15 Batch 1100 Loss 0.0901\n",
            "Epoch 15 Batch 1200 Loss 0.0859\n",
            "Epoch 15 Loss 0.0688\n",
            "Time taken for 1 epoch 53.935967445373535 sec\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mU3Ce8M6I3rz"
      },
      "source": [
        "## Перевод\n",
        "\n",
        "* Функция оценки аналогична циклу обучения, за исключением того, что здесь мы не используем \"teacher forcing\". Входными данными для декодера на каждом временном шаге являются его предыдущие предсказания вместе со скрытым состоянием и выходными данными кодера.\n",
        "* Прекратить прогнозирование, когда модель предскажет *конечный токен*.\n",
        "* И сохранить значения *веса внимания для каждого временного шага*.\n",
        "\n",
        "Примечание: Выходной сигнал энкодера вычисляется только один раз для одного входа."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbQpyYs13jF_"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess_sentence(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden = decoder(dec_input, dec_hidden)\n",
        "\n",
        "    # сохранение весов внимания для последующего построения графика\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result, sentence\n",
        "\n",
        "    # прогнозируемый идентификатор вводится обратно в модель\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result, sentence"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl9zUHzg3jGI"
      },
      "source": [
        "def translate(sentence):\n",
        "  result, sentence = evaluate(sentence)\n",
        "\n",
        "  print('Input: %s' % (sentence))\n",
        "  print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n250XbnjOaqP"
      },
      "source": [
        "## Восстановим последнюю контрольную точку и протестируем"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJpT9D5_OgP6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7dccbc9-3079-496c-bfae-9f55f99f9a5a"
      },
      "source": [
        "# восстановим последнюю контрольную точку из checkpoint_dir\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7f2d3a1f5f90>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrAM0FDomq3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23c3eb58-0b54-4cc8-ca16-e38b1dc6727e"
      },
      "source": [
        "translate('Здесь хорошо.')"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> здесь хорошо . <end>\n",
            "Predicted translation: it's well here . <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bhFfwcIMX5i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1c510b9-1366-4c3b-94e7-01cc1cb7ba19"
      },
      "source": [
        "translate('Я не смогу поехать.')"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> я не смогу поехать . <end>\n",
            "Predicted translation: i can't go . <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSx2iM36EZQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "325e1053-164e-4b0a-9d33-c3a92dbd4db2"
      },
      "source": [
        "translate(u'Вы еще дома?')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> вы еще дома ? <end>\n",
            "Predicted translation: are you still home ? <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3LLCx3ZE0Ls",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6532d97-ab43-4c4d-9909-423122d1b682"
      },
      "source": [
        "translate(u'Вы все еще дома?')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> вы все еще дома ? <end>\n",
            "Predicted translation: are you still home ? <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUQVLVqUE1YW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d809c1-b48a-4dfc-a0fc-9f8b326bff72"
      },
      "source": [
        "translate(u'Попробуй сделать это.')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> попробуй сделать это . <end>\n",
            "Predicted translation: try to do that . <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f09_hUFx9EJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2734258-65e1-46ef-dbb3-d175580305e7"
      },
      "source": [
        "translate(u'Я люблю, когда идет снег.')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> я люблю , когда идет снег . <end>\n",
            "Predicted translation: i like when it rains . <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7c5p8rmkHQG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc3bbd5-a75b-4ea3-dfd6-a677a2d01a5f"
      },
      "source": [
        "translate(u'Я никогда такого не делаю.')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: <start> я никогда такого не делаю . <end>\n",
            "Predicted translation: i never do that . <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Вывод:**  \n",
        "\n",
        "Видно, что короткие предложения переводятся достаточно хорошо. А вот если предложение досаточно длинное, то перевод становится заметно хуже."
      ],
      "metadata": {
        "id": "edybIfglEHOl"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pGtmZF9wEXRN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}